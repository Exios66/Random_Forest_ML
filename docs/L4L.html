<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.24">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jack J. Burleson">
<meta name="dcterms.date" content="2025-11-17">

<title>Random Forest Algorithms: Applications to Large-Scale Datasets</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="L4L_files/libs/clipboard/clipboard.min.js"></script>
<script src="L4L_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="L4L_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="L4L_files/libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="L4L_files/libs/quarto-html/popper.min.js"></script>
<script src="L4L_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="L4L_files/libs/quarto-html/anchor.min.js"></script>
<link href="L4L_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="L4L_files/libs/quarto-html/quarto-syntax-highlighting-dc55a5b9e770e841cd82e46aadbfb9b0.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="L4L_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="L4L_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="L4L_files/libs/bootstrap/bootstrap-a74871fe4945b66d259aafc266475145.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#key-advantages" id="toc-key-advantages" class="nav-link" data-scroll-target="#key-advantages">Key Advantages</a></li>
  </ul></li>
  <li><a href="#theoretical-foundations" id="toc-theoretical-foundations" class="nav-link" data-scroll-target="#theoretical-foundations">Theoretical Foundations</a>
  <ul class="collapse">
  <li><a href="#bootstrap-aggregation-bagging" id="toc-bootstrap-aggregation-bagging" class="nav-link" data-scroll-target="#bootstrap-aggregation-bagging">Bootstrap Aggregation (Bagging)</a></li>
  <li><a href="#random-feature-selection" id="toc-random-feature-selection" class="nav-link" data-scroll-target="#random-feature-selection">Random Feature Selection</a></li>
  <li><a href="#mathematical-formulation" id="toc-mathematical-formulation" class="nav-link" data-scroll-target="#mathematical-formulation">Mathematical Formulation</a></li>
  </ul></li>
  <li><a href="#implementation-core-components" id="toc-implementation-core-components" class="nav-link" data-scroll-target="#implementation-core-components">Implementation: Core Components</a>
  <ul class="collapse">
  <li><a href="#essential-libraries-and-setup" id="toc-essential-libraries-and-setup" class="nav-link" data-scroll-target="#essential-libraries-and-setup">Essential Libraries and Setup</a></li>
  <li><a href="#data-preparation-for-large-datasets" id="toc-data-preparation-for-large-datasets" class="nav-link" data-scroll-target="#data-preparation-for-large-datasets">Data Preparation for Large Datasets</a></li>
  <li><a href="#random-forest-classifier-critical-implementation" id="toc-random-forest-classifier-critical-implementation" class="nav-link" data-scroll-target="#random-forest-classifier-critical-implementation">Random Forest Classifier: Critical Implementation</a></li>
  <li><a href="#feature-importance-analysis" id="toc-feature-importance-analysis" class="nav-link" data-scroll-target="#feature-importance-analysis">Feature Importance Analysis</a></li>
  <li><a href="#hyperparameter-tuning-for-large-datasets" id="toc-hyperparameter-tuning-for-large-datasets" class="nav-link" data-scroll-target="#hyperparameter-tuning-for-large-datasets">Hyperparameter Tuning for Large Datasets</a></li>
  <li><a href="#random-forest-regressor-regression-applications" id="toc-random-forest-regressor-regression-applications" class="nav-link" data-scroll-target="#random-forest-regressor-regression-applications">Random Forest Regressor: Regression Applications</a></li>
  <li><a href="#handling-imbalanced-datasets" id="toc-handling-imbalanced-datasets" class="nav-link" data-scroll-target="#handling-imbalanced-datasets">Handling Imbalanced Datasets</a></li>
  </ul></li>
  <li><a href="#performance-optimization-for-large-datasets" id="toc-performance-optimization-for-large-datasets" class="nav-link" data-scroll-target="#performance-optimization-for-large-datasets">Performance Optimization for Large Datasets</a>
  <ul class="collapse">
  <li><a href="#incremental-learning-and-memory-efficiency" id="toc-incremental-learning-and-memory-efficiency" class="nav-link" data-scroll-target="#incremental-learning-and-memory-efficiency">Incremental Learning and Memory Efficiency</a></li>
  <li><a href="#parallel-processing-configuration" id="toc-parallel-processing-configuration" class="nav-link" data-scroll-target="#parallel-processing-configuration">Parallel Processing Configuration</a></li>
  </ul></li>
  <li><a href="#datasets-for-random-forest-applications" id="toc-datasets-for-random-forest-applications" class="nav-link" data-scroll-target="#datasets-for-random-forest-applications">Datasets for Random Forest Applications</a>
  <ul class="collapse">
  <li><a href="#publicly-available-large-scale-datasets" id="toc-publicly-available-large-scale-datasets" class="nav-link" data-scroll-target="#publicly-available-large-scale-datasets">Publicly Available Large-Scale Datasets</a></li>
  <li><a href="#dataset-loading-function" id="toc-dataset-loading-function" class="nav-link" data-scroll-target="#dataset-loading-function">Dataset Loading Function</a></li>
  </ul></li>
  <li><a href="#further-machine-learning-resources" id="toc-further-machine-learning-resources" class="nav-link" data-scroll-target="#further-machine-learning-resources">Further Machine Learning Resources</a>
  <ul class="collapse">
  <li><a href="#online-courses-and-tutorials" id="toc-online-courses-and-tutorials" class="nav-link" data-scroll-target="#online-courses-and-tutorials">Online Courses and Tutorials</a></li>
  <li><a href="#books-and-textbooks" id="toc-books-and-textbooks" class="nav-link" data-scroll-target="#books-and-textbooks">Books and Textbooks</a></li>
  <li><a href="#software-and-libraries" id="toc-software-and-libraries" class="nav-link" data-scroll-target="#software-and-libraries">Software and Libraries</a></li>
  <li><a href="#research-communities" id="toc-research-communities" class="nav-link" data-scroll-target="#research-communities">Research Communities</a></li>
  </ul></li>
  <li><a href="#literature-review" id="toc-literature-review" class="nav-link" data-scroll-target="#literature-review">Literature Review</a>
  <ul class="collapse">
  <li><a href="#foundational-papers" id="toc-foundational-papers" class="nav-link" data-scroll-target="#foundational-papers">Foundational Papers</a></li>
  <li><a href="#recent-advances-and-applications" id="toc-recent-advances-and-applications" class="nav-link" data-scroll-target="#recent-advances-and-applications">Recent Advances and Applications</a></li>
  <li><a href="#large-scale-applications" id="toc-large-scale-applications" class="nav-link" data-scroll-target="#large-scale-applications">Large-Scale Applications</a></li>
  <li><a href="#feature-importance-and-interpretability" id="toc-feature-importance-and-interpretability" class="nav-link" data-scroll-target="#feature-importance-and-interpretability">Feature Importance and Interpretability</a></li>
  <li><a href="#theoretical-developments" id="toc-theoretical-developments" class="nav-link" data-scroll-target="#theoretical-developments">Theoretical Developments</a></li>
  </ul></li>
  <li><a href="#gradient-boosting-methods" id="toc-gradient-boosting-methods" class="nav-link" data-scroll-target="#gradient-boosting-methods">Gradient Boosting Methods</a>
  <ul class="collapse">
  <li><a href="#theoretical-foundations-1" id="toc-theoretical-foundations-1" class="nav-link" data-scroll-target="#theoretical-foundations-1">Theoretical Foundations</a></li>
  <li><a href="#xgboost-extreme-gradient-boosting" id="toc-xgboost-extreme-gradient-boosting" class="nav-link" data-scroll-target="#xgboost-extreme-gradient-boosting">XGBoost: Extreme Gradient Boosting</a></li>
  <li><a href="#lightgbm-light-gradient-boosting-machine" id="toc-lightgbm-light-gradient-boosting-machine" class="nav-link" data-scroll-target="#lightgbm-light-gradient-boosting-machine">LightGBM: Light Gradient Boosting Machine</a></li>
  <li><a href="#comparison-random-forest-vs-gradient-boosting" id="toc-comparison-random-forest-vs-gradient-boosting" class="nav-link" data-scroll-target="#comparison-random-forest-vs-gradient-boosting">Comparison: Random Forest vs Gradient Boosting</a></li>
  </ul></li>
  <li><a href="#support-vector-machines-for-large-scale-data" id="toc-support-vector-machines-for-large-scale-data" class="nav-link" data-scroll-target="#support-vector-machines-for-large-scale-data">Support Vector Machines for Large-Scale Data</a>
  <ul class="collapse">
  <li><a href="#linear-svm-with-stochastic-gradient-descent" id="toc-linear-svm-with-stochastic-gradient-descent" class="nav-link" data-scroll-target="#linear-svm-with-stochastic-gradient-descent">Linear SVM with Stochastic Gradient Descent</a></li>
  <li><a href="#kernel-approximation-for-non-linear-svms" id="toc-kernel-approximation-for-non-linear-svms" class="nav-link" data-scroll-target="#kernel-approximation-for-non-linear-svms">Kernel Approximation for Non-Linear SVMs</a></li>
  </ul></li>
  <li><a href="#neural-networks-for-large-scale-learning" id="toc-neural-networks-for-large-scale-learning" class="nav-link" data-scroll-target="#neural-networks-for-large-scale-learning">Neural Networks for Large-Scale Learning</a>
  <ul class="collapse">
  <li><a href="#multi-layer-perceptron-with-scikit-learn" id="toc-multi-layer-perceptron-with-scikit-learn" class="nav-link" data-scroll-target="#multi-layer-perceptron-with-scikit-learn">Multi-Layer Perceptron with scikit-learn</a></li>
  <li><a href="#deep-learning-with-tensorflowkeras-optional" id="toc-deep-learning-with-tensorflowkeras-optional" class="nav-link" data-scroll-target="#deep-learning-with-tensorflowkeras-optional">Deep Learning with TensorFlow/Keras (Optional)</a></li>
  </ul></li>
  <li><a href="#regularized-linear-models" id="toc-regularized-linear-models" class="nav-link" data-scroll-target="#regularized-linear-models">Regularized Linear Models</a>
  <ul class="collapse">
  <li><a href="#ridge-regression" id="toc-ridge-regression" class="nav-link" data-scroll-target="#ridge-regression">Ridge Regression</a></li>
  <li><a href="#elastic-net-combining-l1-and-l2-regularization" id="toc-elastic-net-combining-l1-and-l2-regularization" class="nav-link" data-scroll-target="#elastic-net-combining-l1-and-l2-regularization">Elastic Net: Combining L1 and L2 Regularization</a></li>
  <li><a href="#lasso-for-feature-selection" id="toc-lasso-for-feature-selection" class="nav-link" data-scroll-target="#lasso-for-feature-selection">Lasso for Feature Selection</a></li>
  </ul></li>
  <li><a href="#comparative-analysis-of-ml-techniques" id="toc-comparative-analysis-of-ml-techniques" class="nav-link" data-scroll-target="#comparative-analysis-of-ml-techniques">Comparative Analysis of ML Techniques</a>
  <ul class="collapse">
  <li><a href="#performance-comparison-on-large-datasets" id="toc-performance-comparison-on-large-datasets" class="nav-link" data-scroll-target="#performance-comparison-on-large-datasets">Performance Comparison on Large Datasets</a></li>
  </ul></li>
  <li><a href="#when-to-use-each-technique" id="toc-when-to-use-each-technique" class="nav-link" data-scroll-target="#when-to-use-each-technique">When to Use Each Technique</a>
  <ul class="collapse">
  <li><a href="#decision-guide" id="toc-decision-guide" class="nav-link" data-scroll-target="#decision-guide">Decision Guide</a></li>
  <li><a href="#scalability-considerations" id="toc-scalability-considerations" class="nav-link" data-scroll-target="#scalability-considerations">Scalability Considerations</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a>
  <ul class="collapse">
  <li><a href="#key-takeaways" id="toc-key-takeaways" class="nav-link" data-scroll-target="#key-takeaways">Key Takeaways</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Random Forest Algorithms: Applications to Large-Scale Datasets</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
<p class="subtitle lead">A Comprehensive Analysis of Ensemble Learning Methods</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Jack J. Burleson </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 17, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>Random Forest algorithms represent one of the most robust and widely-applied machine learning techniques for both classification and regression tasks. This document provides a comprehensive examination of Random Forest methodology, its theoretical foundations, practical implementation strategies, and applications to large-scale datasets. Through empirical demonstrations and code examples, we illustrate the effectiveness of ensemble learning approaches in handling complex, high-dimensional data structures while maintaining interpretability and computational efficiency.</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Random Forest, introduced by Breiman (2001), is an ensemble learning method that constructs multiple decision trees during training and outputs the mode of classes (classification) or mean prediction (regression) of the individual trees. The algorithm’s strength lies in its ability to reduce overfitting through the aggregation of diverse tree predictions while maintaining high predictive accuracy across diverse domains.</p>
<section id="key-advantages" class="level3">
<h3 class="anchored" data-anchor-id="key-advantages">Key Advantages</h3>
<ul>
<li><strong>Robustness to Overfitting</strong>: Through bootstrap aggregation and random feature selection</li>
<li><strong>Handling of High-Dimensional Data</strong>: Effective feature selection mechanisms</li>
<li><strong>Non-parametric Nature</strong>: No assumptions about data distribution</li>
<li><strong>Feature Importance</strong>: Built-in mechanisms for variable importance assessment</li>
<li><strong>Scalability</strong>: Efficient parallelization capabilities</li>
</ul>
</section>
</section>
<section id="theoretical-foundations" class="level2">
<h2 class="anchored" data-anchor-id="theoretical-foundations">Theoretical Foundations</h2>
<section id="bootstrap-aggregation-bagging" class="level3">
<h3 class="anchored" data-anchor-id="bootstrap-aggregation-bagging">Bootstrap Aggregation (Bagging)</h3>
<p>Random Forest employs bootstrap aggregation, where each tree is trained on a random subset of the training data sampled with replacement. This process reduces variance and improves generalization performance.</p>
</section>
<section id="random-feature-selection" class="level3">
<h3 class="anchored" data-anchor-id="random-feature-selection">Random Feature Selection</h3>
<p>At each node split, the algorithm considers only a random subset of features, typically <span class="math inline">\(\sqrt{p}\)</span> for classification and <span class="math inline">\(p/3\)</span> for regression, where <span class="math inline">\(p\)</span> is the total number of features. This decorrelates the trees and enhances model diversity.</p>
</section>
<section id="mathematical-formulation" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-formulation">Mathematical Formulation</h3>
<p>For a Random Forest with <span class="math inline">\(B\)</span> trees, the prediction for a new observation <span class="math inline">\(\mathbf{x}\)</span> is:</p>
<p><span class="math display">\[\hat{f}_{RF}(\mathbf{x}) = \frac{1}{B}\sum_{b=1}^{B} T_b(\mathbf{x})\]</span></p>
<p>where <span class="math inline">\(T_b(\mathbf{x})\)</span> represents the prediction from the <span class="math inline">\(b\)</span>-th tree.</p>
</section>
</section>
<section id="implementation-core-components" class="level2">
<h2 class="anchored" data-anchor-id="implementation-core-components">Implementation: Core Components</h2>
<section id="essential-libraries-and-setup" class="level3">
<h3 class="anchored" data-anchor-id="essential-libraries-and-setup">Essential Libraries and Setup</h3>
<div id="setup" class="cell" data-execution_count="1">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, RandomForestRegressor</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, cross_val_score, GridSearchCV</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (accuracy_score, classification_report, </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>                            confusion_matrix, mean_squared_error, r2_score)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification, make_regression</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seed for reproducibility</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="data-preparation-for-large-datasets" class="level3">
<h3 class="anchored" data-anchor-id="data-preparation-for-large-datasets">Data Preparation for Large Datasets</h3>
<div id="data-prep" class="cell" data-execution_count="2">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prepare_large_dataset(n_samples<span class="op">=</span><span class="dv">10000</span>, n_features<span class="op">=</span><span class="dv">50</span>, n_informative<span class="op">=</span><span class="dv">20</span>):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Generate a synthetic large-scale dataset for demonstration.</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">    -----------</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">    n_samples : int</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">        Number of samples</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">    n_features : int</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">        Total number of features</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">    n_informative : int</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">        Number of informative features</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co">    --------</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co">    X, y : tuple</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co">        Feature matrix and target vector</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    X, y <span class="op">=</span> make_classification(</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        n_samples<span class="op">=</span>n_samples,</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>        n_features<span class="op">=</span>n_features,</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        n_informative<span class="op">=</span>n_informative,</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>        n_redundant<span class="op">=</span>n_features <span class="op">-</span> n_informative,</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>        n_clusters_per_class<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X, y</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate large dataset</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> prepare_large_dataset(n_samples<span class="op">=</span><span class="dv">50000</span>, n_features<span class="op">=</span><span class="dv">100</span>, n_informative<span class="op">=</span><span class="dv">40</span>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dataset shape: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Target distribution: </span><span class="sc">{</span>np<span class="sc">.</span>bincount(y)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Dataset shape: (50000, 100)
Target distribution: [25018 24982]</code></pre>
</div>
</div>
</section>
<section id="random-forest-classifier-critical-implementation" class="level3">
<h3 class="anchored" data-anchor-id="random-forest-classifier-critical-implementation">Random Forest Classifier: Critical Implementation</h3>
<div id="rf-classifier" class="cell" data-execution_count="3">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split data into training and testing sets</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize Random Forest with optimized hyperparameters</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>rf_classifier <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,           <span class="co"># Number of trees</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="va">None</span>,              <span class="co"># Maximum depth (None = unlimited)</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">2</span>,         <span class="co"># Minimum samples to split node</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">1</span>,          <span class="co"># Minimum samples in leaf node</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    max_features<span class="op">=</span><span class="st">'sqrt'</span>,         <span class="co"># Number of features to consider (sqrt for classification)</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    bootstrap<span class="op">=</span><span class="va">True</span>,              <span class="co"># Bootstrap sampling</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    oob_score<span class="op">=</span><span class="va">True</span>,              <span class="co"># Out-of-bag score</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>                    <span class="co"># Use all available cores</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>rf_classifier.fit(X_train, y_train)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate performance</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> rf_classifier.predict(X_test)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>oob_score <span class="op">=</span> rf_classifier.oob_score_</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Out-of-Bag Score: </span><span class="sc">{</span>oob_score<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Test Accuracy: 0.9903
Out-of-Bag Score: 0.9852</code></pre>
</div>
</div>
</section>
<section id="feature-importance-analysis" class="level3">
<h3 class="anchored" data-anchor-id="feature-importance-analysis">Feature Importance Analysis</h3>
<div id="cell-feature-importance" class="cell" data-fig-height="8" data-fig-width="10" data-execution_count="4">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract feature importances</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>feature_importances <span class="op">=</span> rf_classifier.feature_importances_</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> np.argsort(feature_importances)[::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize top 20 most important features</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>top_n <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>plt.barh(<span class="bu">range</span>(top_n), feature_importances[indices[:top_n]])</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>plt.yticks(<span class="bu">range</span>(top_n), [<span class="ss">f'Feature </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> indices[:top_n]])</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importance Score'</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Features'</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Top 20 Feature Importances'</span>)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_yaxis()</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div id="feature-importance" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="L4L_files/figure-html/feature-importance-output-1.png" width="949" height="756" class="figure-img" alt="Horizontal bar chart showing feature importance rankings from Random Forest model, with features ranked by importance score" title="Feature Importance Rankings from Random Forest Model"></p>
<figcaption>Feature Importance Rankings from Random Forest Model</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="hyperparameter-tuning-for-large-datasets" class="level3">
<h3 class="anchored" data-anchor-id="hyperparameter-tuning-for-large-datasets">Hyperparameter Tuning for Large Datasets</h3>
<div id="hyperparameter-tuning" class="cell" data-execution_count="5">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define parameter grid for optimization</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: [<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>],</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="dv">10</span>, <span class="dv">20</span>, <span class="va">None</span>],</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_split'</span>: [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>],</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_features'</span>: [<span class="st">'sqrt'</span>, <span class="st">'log2'</span>]</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Use a subset for faster grid search on large datasets</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>X_train_subset <span class="op">=</span> X_train[:<span class="dv">10000</span>]  <span class="co"># Sample for grid search</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>y_train_subset <span class="op">=</span> y_train[:<span class="dv">10000</span>]</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Grid search with cross-validation</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>),</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    param_grid,</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">3</span>,                          <span class="co"># 3-fold cross-validation</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'accuracy'</span>,</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">1</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train_subset, y_train_subset)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Parameters:"</span>, grid_search.best_params_)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Cross-Validation Score:"</span>, grid_search.best_score_)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 3 folds for each of 54 candidates, totalling 162 fits
Best Parameters: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 300}
Best Cross-Validation Score: 0.9834999096790303</code></pre>
</div>
</div>
</section>
<section id="random-forest-regressor-regression-applications" class="level3">
<h3 class="anchored" data-anchor-id="random-forest-regressor-regression-applications">Random Forest Regressor: Regression Applications</h3>
<div id="rf-regressor" class="cell" data-execution_count="6">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate regression dataset</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>X_reg, y_reg <span class="op">=</span> make_regression(</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    n_samples<span class="op">=</span><span class="dv">10000</span>,</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    n_features<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    n_informative<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    noise<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>X_train_reg, X_test_reg, y_train_reg, y_test_reg <span class="op">=</span> train_test_split(</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    X_reg, y_reg, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest Regressor</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>rf_regressor <span class="op">=</span> RandomForestRegressor(</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    max_features<span class="op">=</span><span class="va">None</span>,  <span class="co"># None uses all features (default for regression)</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    bootstrap<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>    oob_score<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>rf_regressor.fit(X_train_reg, y_train_reg)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions and evaluation</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>y_pred_reg <span class="op">=</span> rf_regressor.predict(X_test_reg)</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test_reg, y_pred_reg)</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>r2 <span class="op">=</span> r2_score(y_test_reg, y_pred_reg)</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean Squared Error: </span><span class="sc">{</span>mse<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R² Score: </span><span class="sc">{</span>r2<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Out-of-Bag Score: </span><span class="sc">{</span>rf_regressor<span class="sc">.</span>oob_score_<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Squared Error: 35011.7695
R² Score: 0.6293
Out-of-Bag Score: 0.6184</code></pre>
</div>
</div>
</section>
<section id="handling-imbalanced-datasets" class="level3">
<h3 class="anchored" data-anchor-id="handling-imbalanced-datasets">Handling Imbalanced Datasets</h3>
<div id="imbalanced-data" class="cell" data-execution_count="7">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create imbalanced dataset</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>X_imb, y_imb <span class="op">=</span> make_classification(</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    n_samples<span class="op">=</span><span class="dv">10000</span>,</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    n_features<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    n_informative<span class="op">=</span><span class="dv">15</span>,</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    weights<span class="op">=</span>[<span class="fl">0.9</span>, <span class="fl">0.1</span>],  <span class="co"># 90% class 0, 10% class 1</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>X_train_imb, X_test_imb, y_train_imb, y_test_imb <span class="op">=</span> train_test_split(</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    X_imb, y_imb, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y_imb</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest with class_weight='balanced'</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>rf_balanced <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    class_weight<span class="op">=</span><span class="st">'balanced'</span>,  <span class="co"># Automatically adjust class weights</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>rf_balanced.fit(X_train_imb, y_train_imb)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>y_pred_imb <span class="op">=</span> rf_balanced.predict(X_test_imb)</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report (Balanced Random Forest):"</span>)</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test_imb, y_pred_imb))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Classification Report (Balanced Random Forest):
              precision    recall  f1-score   support

           0       0.92      1.00      0.96      1791
           1       0.98      0.30      0.46       209

    accuracy                           0.93      2000
   macro avg       0.95      0.65      0.71      2000
weighted avg       0.93      0.93      0.91      2000
</code></pre>
</div>
</div>
</section>
</section>
<section id="performance-optimization-for-large-datasets" class="level2">
<h2 class="anchored" data-anchor-id="performance-optimization-for-large-datasets">Performance Optimization for Large Datasets</h2>
<section id="incremental-learning-and-memory-efficiency" class="level3">
<h3 class="anchored" data-anchor-id="incremental-learning-and-memory-efficiency">Incremental Learning and Memory Efficiency</h3>
<div id="memory-optimization" class="cell" data-execution_count="8">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># For very large datasets, consider these strategies:</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Use max_samples parameter to limit bootstrap sample size</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Set max_depth to prevent excessive memory usage</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Use warm_start for incremental training</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>rf_efficient <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">15</span>,              <span class="co"># Limit tree depth</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    max_samples<span class="op">=</span><span class="fl">0.5</span>,           <span class="co"># Use 50% of data for each tree</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    max_features<span class="op">=</span><span class="st">'sqrt'</span>,</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Train on large dataset</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>rf_efficient.fit(X_train, y_train)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Model trained successfully on </span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Memory-efficient configuration completed"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Model trained successfully on 40000 samples
Memory-efficient configuration completed</code></pre>
</div>
</div>
</section>
<section id="parallel-processing-configuration" class="level3">
<h3 class="anchored" data-anchor-id="parallel-processing-configuration">Parallel Processing Configuration</h3>
<div id="parallel-processing" class="cell" data-execution_count="9">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare sequential vs parallel processing</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>X_sample <span class="op">=</span> X_train[:<span class="dv">5000</span>]</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>y_sample <span class="op">=</span> y_train[:<span class="dv">5000</span>]</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Sequential processing</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>rf_seq <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, n_jobs<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>rf_seq.fit(X_sample, y_sample)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>seq_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Parallel processing</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>rf_par <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>rf_par.fit(X_sample, y_sample)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>par_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sequential time: </span><span class="sc">{</span>seq_time<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Parallel time: </span><span class="sc">{</span>par_time<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Speedup: </span><span class="sc">{</span>seq_time<span class="op">/</span>par_time<span class="sc">:.2f}</span><span class="ss">x"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Sequential time: 2.69 seconds
Parallel time: 0.63 seconds
Speedup: 4.27x</code></pre>
</div>
</div>
</section>
</section>
<section id="datasets-for-random-forest-applications" class="level2">
<h2 class="anchored" data-anchor-id="datasets-for-random-forest-applications">Datasets for Random Forest Applications</h2>
<section id="publicly-available-large-scale-datasets" class="level3">
<h3 class="anchored" data-anchor-id="publicly-available-large-scale-datasets">Publicly Available Large-Scale Datasets</h3>
<p>The following datasets are excellent for demonstrating Random Forest algorithms on large-scale problems:</p>
<section id="classification-datasets" class="level4">
<h4 class="anchored" data-anchor-id="classification-datasets">Classification Datasets</h4>
<ol type="1">
<li><strong>UCI Machine Learning Repository</strong>
<ul>
<li>URL: https://archive.ics.uci.edu/</li>
<li>Notable datasets: Covertype, KDD Cup 1999, Adult Census</li>
<li>Access: Direct download via Python <code>sklearn.datasets</code> or manual download</li>
</ul></li>
<li><strong>Kaggle Datasets</strong>
<ul>
<li>URL: https://www.kaggle.com/datasets</li>
<li>Large-scale competitions: Titanic, House Prices, Credit Card Fraud Detection</li>
<li>Access: Requires Kaggle account and API key</li>
</ul></li>
<li><strong>OpenML</strong>
<ul>
<li>URL: https://www.openml.org/</li>
<li>Access via Python: <code>from openml import datasets</code></li>
</ul></li>
</ol>
<div id="dataset-access" class="cell" data-execution_count="10">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Loading UCI datasets via scikit-learn</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_covtype</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    covtype <span class="op">=</span> fetch_covtype()</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Covertype dataset shape: </span><span class="sc">{</span>covtype<span class="sc">.</span>data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Number of classes: </span><span class="sc">{</span><span class="bu">len</span>(np.unique(covtype.target))<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span>:</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Dataset fetch requires internet connection"</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Using OpenML</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> openml.datasets <span class="im">import</span> get_dataset</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># dataset = get_dataset(1)  # Uncomment to fetch specific dataset</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"OpenML integration available"</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Install openml: pip install openml"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Covertype dataset shape: (581012, 54)
Number of classes: 7
Install openml: pip install openml</code></pre>
</div>
</div>
</section>
<section id="regression-datasets" class="level4">
<h4 class="anchored" data-anchor-id="regression-datasets">Regression Datasets</h4>
<ol type="1">
<li><strong>California Housing Dataset</strong> (Built-in scikit-learn)</li>
<li><strong>Boston Housing Dataset</strong> (Historical, now deprecated)</li>
<li><strong>Ames Housing Dataset</strong> (Kaggle)</li>
</ol>
<div id="regression-datasets" class="cell" data-execution_count="11">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_california_housing</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>housing <span class="op">=</span> fetch_california_housing()</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"California Housing dataset shape: </span><span class="sc">{</span>housing<span class="sc">.</span>data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Features: </span><span class="sc">{</span>housing<span class="sc">.</span>feature_names<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>California Housing dataset shape: (20640, 8)
Features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']</code></pre>
</div>
</div>
</section>
</section>
<section id="dataset-loading-function" class="level3">
<h3 class="anchored" data-anchor-id="dataset-loading-function">Dataset Loading Function</h3>
<div id="dataset-loader" class="cell" data-execution_count="12">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_dataset(dataset_name<span class="op">=</span><span class="st">'synthetic'</span>, n_samples<span class="op">=</span><span class="dv">10000</span>):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Unified dataset loading function.</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co">    -----------</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co">    dataset_name : str</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co">        Name of dataset ('synthetic', 'california_housing', etc.)</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co">    n_samples : int</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co">        For synthetic datasets</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="co">    --------</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="co">    X, y : tuple</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="co">        Feature matrix and target</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> dataset_name <span class="op">==</span> <span class="st">'synthetic'</span>:</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>        X, y <span class="op">=</span> make_classification(</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>            n_samples<span class="op">=</span>n_samples,</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>            n_features<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>            n_informative<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>            random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> dataset_name <span class="op">==</span> <span class="st">'california_housing'</span>:</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> fetch_california_housing()</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>        X, y <span class="op">=</span> data.data, data.target</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Unknown dataset: </span><span class="sc">{</span>dataset_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X, y</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
</section>
<section id="further-machine-learning-resources" class="level2">
<h2 class="anchored" data-anchor-id="further-machine-learning-resources">Further Machine Learning Resources</h2>
<section id="online-courses-and-tutorials" class="level3">
<h3 class="anchored" data-anchor-id="online-courses-and-tutorials">Online Courses and Tutorials</h3>
<ol type="1">
<li><strong>Coursera - Machine Learning Specialization</strong>
<ul>
<li>URL: https://www.coursera.org/learn/machine-learning</li>
<li>Covers ensemble methods including Random Forests</li>
</ul></li>
<li><strong>edX - MIT Introduction to Machine Learning</strong>
<ul>
<li>URL: https://www.edx.org/course/introduction-to-machine-learning</li>
<li>Comprehensive coverage of ML fundamentals</li>
</ul></li>
<li><strong>Fast.ai - Practical Deep Learning</strong>
<ul>
<li>URL: https://www.fast.ai/</li>
<li>Modern approach to ML with practical applications</li>
</ul></li>
</ol>
</section>
<section id="books-and-textbooks" class="level3">
<h3 class="anchored" data-anchor-id="books-and-textbooks">Books and Textbooks</h3>
<ol type="1">
<li><strong>“The Elements of Statistical Learning”</strong> by Hastie, Tibshirani, and Friedman
<ul>
<li>Comprehensive treatment of statistical learning methods</li>
<li>Chapter 15 covers Random Forests in detail</li>
</ul></li>
<li><strong>“An Introduction to Statistical Learning”</strong> by James et al.
<ul>
<li>More accessible introduction to ML concepts</li>
<li>Excellent for beginners</li>
</ul></li>
<li><strong>“Hands-On Machine Learning”</strong> by Aurélien Géron
<ul>
<li>Practical implementation focus</li>
<li>Code examples in Python</li>
</ul></li>
</ol>
</section>
<section id="software-and-libraries" class="level3">
<h3 class="anchored" data-anchor-id="software-and-libraries">Software and Libraries</h3>
<ol type="1">
<li><strong>scikit-learn</strong> (Python)
<ul>
<li>Primary library used in this document</li>
<li>Documentation: https://scikit-learn.org/stable/</li>
</ul></li>
<li><strong>XGBoost</strong> (Gradient Boosting)
<ul>
<li>Advanced ensemble method</li>
<li>URL: https://xgboost.readthedocs.io/</li>
</ul></li>
<li><strong>LightGBM</strong> (Microsoft)
<ul>
<li>Fast gradient boosting framework</li>
<li>URL: https://lightgbm.readthedocs.io/</li>
</ul></li>
<li><strong>R - randomForest package</strong>
<ul>
<li>Original implementation by Breiman</li>
<li>Comprehensive R documentation</li>
</ul></li>
</ol>
</section>
<section id="research-communities" class="level3">
<h3 class="anchored" data-anchor-id="research-communities">Research Communities</h3>
<ol type="1">
<li><strong>Papers with Code</strong>
<ul>
<li>URL: https://paperswithcode.com/</li>
<li>Latest research papers with implementations</li>
</ul></li>
<li><strong>arXiv Machine Learning</strong>
<ul>
<li>URL: https://arxiv.org/list/cs.LG/recent</li>
<li>Preprint repository for ML research</li>
</ul></li>
<li><strong>Google Scholar</strong>
<ul>
<li>Search for “Random Forest” and related terms</li>
<li>Track citations and related work</li>
</ul></li>
</ol>
</section>
</section>
<section id="literature-review" class="level2">
<h2 class="anchored" data-anchor-id="literature-review">Literature Review</h2>
<section id="foundational-papers" class="level3">
<h3 class="anchored" data-anchor-id="foundational-papers">Foundational Papers</h3>
<ol type="1">
<li><strong>Breiman, L. (2001). “Random Forests.” <em>Machine Learning</em>, 45(1), 5-32.</strong>
<ul>
<li>Original paper introducing Random Forest algorithm</li>
<li>Theoretical foundations and empirical evaluations</li>
<li>DOI: 10.1023/A:1010933404324</li>
</ul></li>
<li><strong>Ho, T. K. (1995). “Random Decision Forests.” <em>Proceedings of the 3rd International Conference on Document Analysis and Recognition</em>, 278-282.</strong>
<ul>
<li>Early work on random decision forests</li>
<li>Precursor to Breiman’s Random Forest</li>
</ul></li>
<li><strong>Breiman, L. (1996). “Bagging Predictors.” <em>Machine Learning</em>, 24(2), 123-140.</strong>
<ul>
<li>Introduction to bootstrap aggregation</li>
<li>Foundation for ensemble methods</li>
<li>DOI: 10.1023/A:1018054314350</li>
</ul></li>
</ol>
</section>
<section id="recent-advances-and-applications" class="level3">
<h3 class="anchored" data-anchor-id="recent-advances-and-applications">Recent Advances and Applications</h3>
<ol start="4" type="1">
<li><strong>Biau, G., &amp; Scornet, E. (2016). “A Random Forest Guided Tour.” <em>Test</em>, 25(2), 197-227.</strong>
<ul>
<li>Comprehensive review of Random Forest theory</li>
<li>Statistical properties and consistency results</li>
<li>DOI: 10.1007/s11749-016-0481-7</li>
</ul></li>
<li><strong>Wright, M. N., &amp; Ziegler, A. (2017). “ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R.” <em>Journal of Statistical Software</em>, 77(1), 1-17.</strong>
<ul>
<li>Efficient implementation for high-dimensional data</li>
<li>Performance optimizations</li>
<li>DOI: 10.18637/jss.v077.i01</li>
</ul></li>
<li><strong>Probst, P., Boulesteix, A. L., &amp; Bischl, B. (2019). “Tunability: Importance of Hyperparameters of Machine Learning Algorithms.” <em>Journal of Machine Learning Research</em>, 20(53), 1-32.</strong>
<ul>
<li>Analysis of hyperparameter importance</li>
<li>Includes Random Forest hyperparameter sensitivity</li>
<li>URL: http://jmlr.org/papers/v20/18-444.html</li>
</ul></li>
</ol>
</section>
<section id="large-scale-applications" class="level3">
<h3 class="anchored" data-anchor-id="large-scale-applications">Large-Scale Applications</h3>
<ol start="7" type="1">
<li><strong>Caruana, R., &amp; Niculescu-Mizil, A. (2006). “An Empirical Comparison of Supervised Learning Algorithms.” <em>Proceedings of the 23rd International Conference on Machine Learning</em>, 161-168.</strong>
<ul>
<li>Comparative study including Random Forests</li>
<li>Performance across multiple datasets</li>
</ul></li>
<li><strong>Fernández-Delgado, M., et al.&nbsp;(2014). “Do We Need Hundreds of Classifiers to Solve Real World Classification Problems?” <em>Journal of Machine Learning Research</em>, 15, 3133-3181.</strong>
<ul>
<li>Large-scale comparison of classifiers</li>
<li>Random Forest performance analysis</li>
</ul></li>
</ol>
</section>
<section id="feature-importance-and-interpretability" class="level3">
<h3 class="anchored" data-anchor-id="feature-importance-and-interpretability">Feature Importance and Interpretability</h3>
<ol start="9" type="1">
<li><strong>Strobl, C., et al.&nbsp;(2007). “Bias in Random Forest Variable Importance Measures: Illustrations, Sources and a Solution.” <em>BMC Bioinformatics</em>, 8(1), 25.</strong>
<ul>
<li>Critical analysis of variable importance measures</li>
<li>Solutions for categorical variables</li>
<li>DOI: 10.1186/1471-2105-8-25</li>
</ul></li>
<li><strong>Lundberg, S. M., &amp; Lee, S. I. (2017). “A Unified Approach to Interpreting Model Predictions.” <em>Advances in Neural Information Processing Systems</em>, 30.</strong>
<ul>
<li>SHAP values for model interpretation</li>
<li>Applicable to Random Forest models</li>
</ul></li>
</ol>
</section>
<section id="theoretical-developments" class="level3">
<h3 class="anchored" data-anchor-id="theoretical-developments">Theoretical Developments</h3>
<ol start="11" type="1">
<li><strong>Scornet, E., Biau, G., &amp; Vert, J. P. (2015). “Consistency of Random Forests.” <em>The Annals of Statistics</em>, 43(4), 1716-1741.</strong>
<ul>
<li>Theoretical consistency results</li>
<li>Asymptotic properties</li>
<li>DOI: 10.1214/15-AOS1321</li>
</ul></li>
<li><strong>Mentch, L., &amp; Hooker, G. (2016). “Quantifying Uncertainty in Random Forests via Confidence Intervals and Hypothesis Tests.” <em>Journal of Machine Learning Research</em>, 17(26), 1-41.</strong>
<ul>
<li>Statistical inference for Random Forests</li>
<li>Confidence intervals and hypothesis testing</li>
</ul></li>
</ol>
</section>
</section>
<section id="gradient-boosting-methods" class="level2">
<h2 class="anchored" data-anchor-id="gradient-boosting-methods">Gradient Boosting Methods</h2>
<p>Gradient Boosting represents another powerful ensemble learning paradigm that sequentially builds models to correct errors from previous iterations. Unlike Random Forests, which use parallel tree construction, gradient boosting employs sequential, additive modeling to minimize prediction errors.</p>
<section id="theoretical-foundations-1" class="level3">
<h3 class="anchored" data-anchor-id="theoretical-foundations-1">Theoretical Foundations</h3>
<p>Gradient Boosting iteratively fits weak learners (typically decision trees) to the negative gradient of a loss function. The algorithm minimizes:</p>
<p><span class="math display">\[L(y, F(x)) = \sum_{i=1}^{n} L(y_i, F(x_i))\]</span></p>
<p>where <span class="math inline">\(F(x) = \sum_{m=1}^{M} \gamma_m h_m(x)\)</span> represents the additive model, and <span class="math inline">\(h_m(x)\)</span> are the base learners.</p>
</section>
<section id="xgboost-extreme-gradient-boosting" class="level3">
<h3 class="anchored" data-anchor-id="xgboost-extreme-gradient-boosting">XGBoost: Extreme Gradient Boosting</h3>
<p>XGBoost extends gradient boosting with regularization, parallel processing, and efficient tree construction algorithms.</p>
<div id="xgboost-implementation" class="cell" data-execution_count="13">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data (outside try block so variables are always available)</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>X_train_gb, X_test_gb, y_train_gb, y_test_gb <span class="op">=</span> train_test_split(</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, mean_squared_error</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># XGBoost Classifier</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    xgb_classifier <span class="op">=</span> xgb.XGBClassifier(</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>        n_estimators<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>        max_depth<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>        learning_rate<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>        subsample<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>        colsample_bytree<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>        n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>        tree_method<span class="op">=</span><span class="st">'hist'</span>  <span class="co"># Efficient histogram-based algorithm</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    xgb_classifier.fit(X_train_gb, y_train_gb)</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>    y_pred_xgb <span class="op">=</span> xgb_classifier.predict(X_test_gb)</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>    xgb_accuracy <span class="op">=</span> accuracy_score(y_test_gb, y_pred_xgb)</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"XGBoost Accuracy: </span><span class="sc">{</span>xgb_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Feature Importance (Top 5):"</span>)</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>    feature_imp <span class="op">=</span> xgb_classifier.feature_importances_</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>    top_indices <span class="op">=</span> np.argsort(feature_imp)[::<span class="op">-</span><span class="dv">1</span>][:<span class="dv">5</span>]</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> top_indices:</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Feature </span><span class="sc">{</span>idx<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>feature_imp[idx]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"XGBoost not installed. Install with: pip install xgboost"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>XGBoost not installed. Install with: pip install xgboost</code></pre>
</div>
</div>
</section>
<section id="lightgbm-light-gradient-boosting-machine" class="level3">
<h3 class="anchored" data-anchor-id="lightgbm-light-gradient-boosting-machine">LightGBM: Light Gradient Boosting Machine</h3>
<p>LightGBM uses gradient-based one-side sampling (GOSS) and exclusive feature bundling (EFB) for improved efficiency on large datasets.</p>
<div id="lightgbm-implementation" class="cell" data-execution_count="14">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> lightgbm <span class="im">as</span> lgb</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># LightGBM Classifier</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    lgb_classifier <span class="op">=</span> lgb.LGBMClassifier(</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>        n_estimators<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>        max_depth<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        learning_rate<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        subsample<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>        colsample_bytree<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>        n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>        verbose<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    lgb_classifier.fit(X_train_gb, y_train_gb)</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    y_pred_lgb <span class="op">=</span> lgb_classifier.predict(X_test_gb)</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    lgb_accuracy <span class="op">=</span> accuracy_score(y_test_gb, y_pred_lgb)</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"LightGBM Accuracy: </span><span class="sc">{</span>lgb_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Training time advantage: LightGBM is typically faster than XGBoost"</span>)</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"LightGBM not installed. Install with: pip install lightgbm"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>LightGBM not installed. Install with: pip install lightgbm</code></pre>
</div>
</div>
</section>
<section id="comparison-random-forest-vs-gradient-boosting" class="level3">
<h3 class="anchored" data-anchor-id="comparison-random-forest-vs-gradient-boosting">Comparison: Random Forest vs Gradient Boosting</h3>
<div id="ensemble-comparison" class="cell" data-execution_count="15">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare smaller subset for fair comparison</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>X_comp <span class="op">=</span> X_train_gb[:<span class="dv">10000</span>]</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>y_comp <span class="op">=</span> y_train_gb[:<span class="dv">10000</span>]</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>rf_comp <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>rf_comp.fit(X_comp, y_comp)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>rf_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a><span class="co"># XGBoost</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> time.time()</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>    xgb_comp <span class="op">=</span> xgb.XGBClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>, tree_method<span class="op">=</span><span class="st">'hist'</span>)</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>    xgb_comp.fit(X_comp, y_comp)</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>    xgb_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Training Time Comparison (10,000 samples):"</span>)</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Random Forest: </span><span class="sc">{</span>rf_time<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  XGBoost: </span><span class="sc">{</span>xgb_time<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Speedup: </span><span class="sc">{</span>rf_time<span class="op">/</span>xgb_time<span class="sc">:.2f}</span><span class="ss">x"</span>)</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"XGBoost comparison requires xgboost installation"</span>)</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"XGBoost comparison error: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>XGBoost comparison requires xgboost installation</code></pre>
</div>
</div>
</section>
</section>
<section id="support-vector-machines-for-large-scale-data" class="level2">
<h2 class="anchored" data-anchor-id="support-vector-machines-for-large-scale-data">Support Vector Machines for Large-Scale Data</h2>
<p>Support Vector Machines (SVMs) are powerful for classification and regression, but traditional implementations scale poorly with large datasets. Modern approaches use kernel approximations and linear SVMs for scalability.</p>
<section id="linear-svm-with-stochastic-gradient-descent" class="level3">
<h3 class="anchored" data-anchor-id="linear-svm-with-stochastic-gradient-descent">Linear SVM with Stochastic Gradient Descent</h3>
<div id="linear-svm" class="cell" data-execution_count="16">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> SGDClassifier</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear SVM using SGD (scales to millions of samples)</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.fit_transform(X_train_gb)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test_gb)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>svm_sgd <span class="op">=</span> SGDClassifier(</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    loss<span class="op">=</span><span class="st">'hinge'</span>,           <span class="co"># SVM loss</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.0001</span>,            <span class="co"># Regularization parameter</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    max_iter<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>svm_sgd.fit(X_train_scaled, y_train_gb)</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>y_pred_svm <span class="op">=</span> svm_sgd.predict(X_test_scaled)</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>svm_accuracy <span class="op">=</span> accuracy_score(y_test_gb, y_pred_svm)</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Linear SVM (SGD) Accuracy: </span><span class="sc">{</span>svm_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Memory efficient: Suitable for datasets with millions of samples"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Linear SVM (SGD) Accuracy: 0.9774
Memory efficient: Suitable for datasets with millions of samples</code></pre>
</div>
</div>
</section>
<section id="kernel-approximation-for-non-linear-svms" class="level3">
<h3 class="anchored" data-anchor-id="kernel-approximation-for-non-linear-svms">Kernel Approximation for Non-Linear SVMs</h3>
<div id="kernel-approximation" class="cell" data-execution_count="17">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.kernel_approximation <span class="im">import</span> RBFSampler, Nystroem</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co"># RBF Kernel approximation</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>rbf_sampler <span class="op">=</span> RBFSampler(</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    gamma<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    n_components<span class="op">=</span><span class="dv">100</span>,  <span class="co"># Number of random features</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>X_train_rbf <span class="op">=</span> rbf_sampler.fit_transform(X_train_scaled)</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>X_test_rbf <span class="op">=</span> rbf_sampler.transform(X_test_scaled)</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>svm_rbf <span class="op">=</span> SGDClassifier(loss<span class="op">=</span><span class="st">'hinge'</span>, alpha<span class="op">=</span><span class="fl">0.0001</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>svm_rbf.fit(X_train_rbf, y_train_gb)</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>y_pred_rbf <span class="op">=</span> svm_rbf.predict(X_test_rbf)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>rbf_accuracy <span class="op">=</span> accuracy_score(y_test_gb, y_pred_rbf)</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"RBF Kernel Approximation Accuracy: </span><span class="sc">{</span>rbf_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Enables non-linear SVMs on large datasets"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>RBF Kernel Approximation Accuracy: 0.5006
Enables non-linear SVMs on large datasets</code></pre>
</div>
</div>
</section>
</section>
<section id="neural-networks-for-large-scale-learning" class="level2">
<h2 class="anchored" data-anchor-id="neural-networks-for-large-scale-learning">Neural Networks for Large-Scale Learning</h2>
<p>Deep learning approaches, particularly feedforward neural networks, can effectively handle large datasets when properly configured with regularization and efficient optimization.</p>
<section id="multi-layer-perceptron-with-scikit-learn" class="level3">
<h3 class="anchored" data-anchor-id="multi-layer-perceptron-with-scikit-learn">Multi-Layer Perceptron with scikit-learn</h3>
<div id="mlp-classifier" class="cell" data-execution_count="18">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Multi-layer Perceptron</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>mlp <span class="op">=</span> MLPClassifier(</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>    hidden_layer_sizes<span class="op">=</span>(<span class="dv">100</span>, <span class="dv">50</span>),  <span class="co"># Two hidden layers</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    activation<span class="op">=</span><span class="st">'relu'</span>,</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    solver<span class="op">=</span><span class="st">'adam'</span>,                <span class="co"># Efficient for large datasets</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.0001</span>,                 <span class="co"># L2 regularization</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">200</span>,               <span class="co"># Mini-batch size</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="st">'adaptive'</span>,</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>    max_iter<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>    early_stopping<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>    validation_fraction<span class="op">=</span><span class="fl">0.1</span></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>mlp.fit(X_train_scaled, y_train_gb)</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>y_pred_mlp <span class="op">=</span> mlp.predict(X_test_scaled)</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>mlp_accuracy <span class="op">=</span> accuracy_score(y_test_gb, y_pred_mlp)</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MLP Accuracy: </span><span class="sc">{</span>mlp_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Architecture: </span><span class="sc">{</span>mlp<span class="sc">.</span>hidden_layer_sizes<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of iterations: </span><span class="sc">{</span>mlp<span class="sc">.</span>n_iter_<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>MLP Accuracy: 0.9947
Architecture: (100, 50)
Number of iterations: 21</code></pre>
</div>
</div>
</section>
<section id="deep-learning-with-tensorflowkeras-optional" class="level3">
<h3 class="anchored" data-anchor-id="deep-learning-with-tensorflowkeras-optional">Deep Learning with TensorFlow/Keras (Optional)</h3>
<div id="deep-learning" class="cell" data-execution_count="19">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Uncomment to use TensorFlow/Keras</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="co">try:</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co">    import tensorflow as tf</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="co">    from tensorflow import keras</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="co">    from tensorflow.keras import layers</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="co">    # Build neural network</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="co">    model = keras.Sequential([</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="co">        layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="co">        layers.Dropout(0.3),</span></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a><span class="co">        layers.Dense(64, activation='relu'),</span></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a><span class="co">        layers.Dropout(0.3),</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a><span class="co">        layers.Dense(1, activation='sigmoid')</span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a><span class="co">    ])</span></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a><span class="co">    model.compile(</span></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a><span class="co">        optimizer='adam',</span></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a><span class="co">        loss='binary_crossentropy',</span></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a><span class="co">        metrics=['accuracy']</span></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a><span class="co">    )</span></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a><span class="co">    # Train model</span></span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a><span class="co">    history = model.fit(</span></span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a><span class="co">        X_train_scaled, y_train_gb,</span></span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a><span class="co">        epochs=50,</span></span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a><span class="co">        batch_size=256,</span></span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a><span class="co">        validation_split=0.2,</span></span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a><span class="co">        verbose=0</span></span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a><span class="co">    )</span></span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a><span class="co">    # Evaluate</span></span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a><span class="co">    test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test_gb, verbose=0)</span></span>
<span id="cb34-34"><a href="#cb34-34" aria-hidden="true" tabindex="-1"></a><span class="co">    print(f"Deep Neural Network Accuracy: {test_accuracy:.4f}")</span></span>
<span id="cb34-35"><a href="#cb34-35" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb34-36"><a href="#cb34-36" aria-hidden="true" tabindex="-1"></a><span class="co">except ImportError:</span></span>
<span id="cb34-37"><a href="#cb34-37" aria-hidden="true" tabindex="-1"></a><span class="co">    print("TensorFlow not installed. Install with: pip install tensorflow")</span></span>
<span id="cb34-38"><a href="#cb34-38" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
</section>
<section id="regularized-linear-models" class="level2">
<h2 class="anchored" data-anchor-id="regularized-linear-models">Regularized Linear Models</h2>
<p>Linear models with regularization (Ridge, Lasso, Elastic Net) are highly scalable and provide interpretable results, making them excellent baselines for large-scale problems.</p>
<section id="ridge-regression" class="level3">
<h3 class="anchored" data-anchor-id="ridge-regression">Ridge Regression</h3>
<div id="ridge-regression" class="cell" data-execution_count="20">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge, RidgeClassifier</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Ridge Regression for continuous targets</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>X_reg_train, X_reg_test, y_reg_train, y_reg_test <span class="op">=</span> train_test_split(</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    X_reg, y_reg, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>ridge_reg <span class="op">=</span> Ridge(alpha<span class="op">=</span><span class="fl">1.0</span>, solver<span class="op">=</span><span class="st">'sag'</span>, random_state<span class="op">=</span><span class="dv">42</span>)  <span class="co"># SAG for large datasets</span></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>ridge_reg.fit(X_reg_train, y_reg_train)</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>y_pred_ridge <span class="op">=</span> ridge_reg.predict(X_reg_test)</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>ridge_r2 <span class="op">=</span> r2_score(y_reg_test, y_pred_ridge)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Ridge Regression R²: </span><span class="sc">{</span>ridge_r2<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Highly scalable to millions of samples"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Ridge Regression R²: 0.9989
Highly scalable to millions of samples</code></pre>
</div>
</div>
</section>
<section id="elastic-net-combining-l1-and-l2-regularization" class="level3">
<h3 class="anchored" data-anchor-id="elastic-net-combining-l1-and-l2-regularization">Elastic Net: Combining L1 and L2 Regularization</h3>
<div id="elastic-net" class="cell" data-execution_count="21">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> ElasticNet, ElasticNetCV</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Elastic Net with cross-validation for hyperparameter tuning</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>elastic_net <span class="op">=</span> ElasticNetCV(</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>    l1_ratio<span class="op">=</span>[<span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>, <span class="fl">0.9</span>, <span class="fl">0.95</span>, <span class="fl">0.99</span>, <span class="fl">1.0</span>],</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>elastic_net.fit(X_reg_train, y_reg_train)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>y_pred_en <span class="op">=</span> elastic_net.predict(X_reg_test)</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>en_r2 <span class="op">=</span> r2_score(y_reg_test, y_pred_en)</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Elastic Net R²: </span><span class="sc">{</span>en_r2<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimal L1 ratio: </span><span class="sc">{</span>elastic_net<span class="sc">.</span>l1_ratio_<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Combines benefits of Ridge and Lasso regularization"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Elastic Net R²: 0.9989
Optimal L1 ratio: 1.0000
Combines benefits of Ridge and Lasso regularization</code></pre>
</div>
</div>
</section>
<section id="lasso-for-feature-selection" class="level3">
<h3 class="anchored" data-anchor-id="lasso-for-feature-selection">Lasso for Feature Selection</h3>
<div id="lasso-feature-selection" class="cell" data-execution_count="22">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Lasso, LassoCV</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Lasso with cross-validation</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>lasso <span class="op">=</span> LassoCV(cv<span class="op">=</span><span class="dv">5</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>, max_iter<span class="op">=</span><span class="dv">2000</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>lasso.fit(X_reg_train, y_reg_train)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Count non-zero coefficients (selected features)</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>n_selected <span class="op">=</span> np.<span class="bu">sum</span>(lasso.coef_ <span class="op">!=</span> <span class="dv">0</span>)</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>total_features <span class="op">=</span> <span class="bu">len</span>(lasso.coef_)</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>y_pred_lasso <span class="op">=</span> lasso.predict(X_reg_test)</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>lasso_r2 <span class="op">=</span> r2_score(y_reg_test, y_pred_lasso)</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Lasso R²: </span><span class="sc">{</span>lasso_r2<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Selected features: </span><span class="sc">{</span>n_selected<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>total_features<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span>n_selected<span class="op">/</span>total_features<span class="sc">:.1f}</span><span class="ss">%)"</span>)</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Automatic feature selection through L1 regularization"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Lasso R²: 0.9989
Selected features: 39/50 (78.0%)
Automatic feature selection through L1 regularization</code></pre>
</div>
</div>
</section>
</section>
<section id="comparative-analysis-of-ml-techniques" class="level2">
<h2 class="anchored" data-anchor-id="comparative-analysis-of-ml-techniques">Comparative Analysis of ML Techniques</h2>
<section id="performance-comparison-on-large-datasets" class="level3">
<h3 class="anchored" data-anchor-id="performance-comparison-on-large-datasets">Performance Comparison on Large Datasets</h3>
<div id="cell-ml-comparison" class="cell" data-fig-height="6" data-fig-width="10" data-execution_count="23">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare multiple algorithms</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>algorithms <span class="op">=</span> {}</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {}</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>rf_comp <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>rf_comp.fit(X_train_gb[:<span class="dv">20000</span>], y_train_gb[:<span class="dv">20000</span>])</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'Random Forest'</span>] <span class="op">=</span> accuracy_score(y_test_gb, rf_comp.predict(X_test_gb))</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="co"># XGBoost</span></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>    xgb_comp <span class="op">=</span> xgb.XGBClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>, tree_method<span class="op">=</span><span class="st">'hist'</span>)</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>    xgb_comp.fit(X_train_gb[:<span class="dv">20000</span>], y_train_gb[:<span class="dv">20000</span>])</span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>    results[<span class="st">'XGBoost'</span>] <span class="op">=</span> accuracy_score(y_test_gb, xgb_comp.predict(X_test_gb))</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear SVM</span></span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'Linear SVM'</span>] <span class="op">=</span> svm_accuracy</span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-24"><a href="#cb41-24" aria-hidden="true" tabindex="-1"></a><span class="co"># MLP</span></span>
<span id="cb41-25"><a href="#cb41-25" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'MLP'</span>] <span class="op">=</span> mlp_accuracy</span>
<span id="cb41-26"><a href="#cb41-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-27"><a href="#cb41-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize comparison</span></span>
<span id="cb41-28"><a href="#cb41-28" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> results:</span>
<span id="cb41-29"><a href="#cb41-29" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb41-30"><a href="#cb41-30" aria-hidden="true" tabindex="-1"></a>    algorithms <span class="op">=</span> <span class="bu">list</span>(results.keys())</span>
<span id="cb41-31"><a href="#cb41-31" aria-hidden="true" tabindex="-1"></a>    accuracies <span class="op">=</span> <span class="bu">list</span>(results.values())</span>
<span id="cb41-32"><a href="#cb41-32" aria-hidden="true" tabindex="-1"></a>    colors <span class="op">=</span> [<span class="st">'#667eea'</span>, <span class="st">'#764ba2'</span>, <span class="st">'#f093fb'</span>, <span class="st">'#4facfe'</span>, <span class="st">'#00f2fe'</span>]</span>
<span id="cb41-33"><a href="#cb41-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb41-34"><a href="#cb41-34" aria-hidden="true" tabindex="-1"></a>    bars <span class="op">=</span> plt.bar(algorithms, accuracies, color<span class="op">=</span>colors[:<span class="bu">len</span>(algorithms)])</span>
<span id="cb41-35"><a href="#cb41-35" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb41-36"><a href="#cb41-36" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Machine Learning Algorithm Comparison'</span>)</span>
<span id="cb41-37"><a href="#cb41-37" aria-hidden="true" tabindex="-1"></a>    plt.ylim([<span class="bu">min</span>(accuracies) <span class="op">-</span> <span class="fl">0.05</span>, <span class="bu">max</span>(accuracies) <span class="op">+</span> <span class="fl">0.05</span>])</span>
<span id="cb41-38"><a href="#cb41-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb41-39"><a href="#cb41-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add value labels on bars</span></span>
<span id="cb41-40"><a href="#cb41-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> bar, acc <span class="kw">in</span> <span class="bu">zip</span>(bars, accuracies):</span>
<span id="cb41-41"><a href="#cb41-41" aria-hidden="true" tabindex="-1"></a>        plt.text(bar.get_x() <span class="op">+</span> bar.get_width()<span class="op">/</span><span class="dv">2</span>, bar.get_height() <span class="op">+</span> <span class="fl">0.01</span>,</span>
<span id="cb41-42"><a href="#cb41-42" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f'</span><span class="sc">{</span>acc<span class="sc">:.3f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>)</span>
<span id="cb41-43"><a href="#cb41-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb41-44"><a href="#cb41-44" aria-hidden="true" tabindex="-1"></a>    plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb41-45"><a href="#cb41-45" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb41-46"><a href="#cb41-46" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div id="ml-comparison" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p>
  <img src="L4L_files/figure-html/ml-comparison-output-1.png" width="949" height="566" class="figure-img" alt="Bar chart comparing accuracy of ML techniques on a large-scale dataset" title="Comparison of ML Techniques on Large-Scale Dataset">
</p>
<figcaption>Comparison of ML Techniques on Large-Scale Dataset</figcaption>
</figure>
</div>
</div>
</section>
</section>
<section id="when-to-use-each-technique" class="level2">
<h2 class="anchored" data-anchor-id="when-to-use-each-technique">When to Use Each Technique</h2>
<section id="decision-guide" class="level3">
<h3 class="anchored" data-anchor-id="decision-guide">Decision Guide</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 24%">
<col style="width: 22%">
<col style="width: 24%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>Technique</th>
<th>Best For</th>
<th>Strengths</th>
<th>Limitations</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Random Forest</strong></td>
<td>Baseline, feature importance, interpretability</td>
<td>Robust, parallelizable, handles mixed data types</td>
<td>Memory intensive, slower than gradient boosting</td>
</tr>
<tr class="even">
<td><strong>XGBoost/LightGBM</strong></td>
<td>High accuracy, competitions, structured data</td>
<td>State-of-the-art performance, efficient</td>
<td>More hyperparameters, less interpretable</td>
</tr>
<tr class="odd">
<td><strong>Linear SVM</strong></td>
<td>Text classification, high-dimensional sparse data</td>
<td>Memory efficient, fast training</td>
<td>Limited to linear or approximated kernels</td>
</tr>
<tr class="even">
<td><strong>Neural Networks</strong></td>
<td>Complex patterns, unstructured data</td>
<td>Flexible, can learn non-linear relationships</td>
<td>Requires more data, longer training time</td>
</tr>
<tr class="odd">
<td><strong>Regularized Linear Models</strong></td>
<td>Baseline, interpretability, feature selection</td>
<td>Fast, interpretable, scalable</td>
<td>Limited to linear relationships</td>
</tr>
</tbody>
</table>
</section>
<section id="scalability-considerations" class="level3">
<h3 class="anchored" data-anchor-id="scalability-considerations">Scalability Considerations</h3>
<div id="scalability-analysis" class="cell" data-execution_count="24">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Scalability Analysis for Large Datasets:"</span>)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">1. Random Forest:"</span>)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Memory: O(n × m × trees)"</span>)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Training: O(n × m × log(m) × trees)"</span>)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Parallelizable: Yes"</span>)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">2. Gradient Boosting (XGBoost/LightGBM):"</span>)</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Memory: O(n × m)"</span>)</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Training: O(n × m × log(m) × iterations)"</span>)</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Parallelizable: Yes (tree-level)"</span>)</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">3. Linear SVM (SGD):"</span>)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Memory: O(m)"</span>)</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Training: O(n × m × iterations)"</span>)</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Parallelizable: Yes (sample-level)"</span>)</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">4. Neural Networks:"</span>)</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Memory: O(parameters)"</span>)</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Training: O(n × parameters × epochs)"</span>)</span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Parallelizable: Yes (GPU acceleration)"</span>)</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">5. Regularized Linear Models:"</span>)</span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Memory: O(m)"</span>)</span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Training: O(n × m × iterations)"</span>)</span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Parallelizable: Yes"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Scalability Analysis for Large Datasets:

1. Random Forest:
   - Memory: O(n × m × trees)
   - Training: O(n × m × log(m) × trees)
   - Parallelizable: Yes

2. Gradient Boosting (XGBoost/LightGBM):
   - Memory: O(n × m)
   - Training: O(n × m × log(m) × iterations)
   - Parallelizable: Yes (tree-level)

3. Linear SVM (SGD):
   - Memory: O(m)
   - Training: O(n × m × iterations)
   - Parallelizable: Yes (sample-level)

4. Neural Networks:
   - Memory: O(parameters)
   - Training: O(n × parameters × epochs)
   - Parallelizable: Yes (GPU acceleration)

5. Regularized Linear Models:
   - Memory: O(m)
   - Training: O(n × m × iterations)
   - Parallelizable: Yes</code></pre>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Random Forest algorithms represent a powerful and versatile tool in the machine learning practitioner’s toolkit. Through bootstrap aggregation and random feature selection, these ensemble methods achieve robust performance across diverse application domains while maintaining computational efficiency and interpretability through feature importance measures.</p>
<p>The demonstrated implementations illustrate key aspects of Random Forest methodology, including hyperparameter optimization, handling of large-scale datasets, and performance evaluation. As machine learning continues to evolve, Random Forests remain a reliable baseline method, particularly valuable for their ability to handle high-dimensional data, provide feature importance insights, and deliver strong predictive performance with minimal preprocessing requirements.</p>
<section id="key-takeaways" class="level3">
<h3 class="anchored" data-anchor-id="key-takeaways">Key Takeaways</h3>
<ul>
<li>Random Forests excel at handling large, high-dimensional datasets</li>
<li>Feature importance measures provide valuable interpretability</li>
<li>Proper hyperparameter tuning significantly impacts performance</li>
<li>Parallel processing enables efficient training on large datasets</li>
<li>The method serves as an excellent baseline for comparison with more complex models</li>
</ul>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<p>All cited literature is listed in the Literature Review section above. For comprehensive bibliographic information, readers are encouraged to consult the original publications through their respective digital object identifiers (DOIs) or publication URLs.</p>
<hr>
<p><em>This document was generated using Quarto. For reproducible research, all code chunks can be executed to regenerate the analyses and visualizations presented herein.</em></p>
<!-- -->

</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb44" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Random Forest Algorithms: Applications to Large-Scale Datasets"</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "A Comprehensive Analysis of Ensemble Learning Methods"</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Jack J. Burleson"</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> today</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> </span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-depth: 3</span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-location: left</span></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: show</span></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a><span class="co">    theme: cosmo</span></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a><span class="co">    include-in-header: |</span></span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a><span class="co">      &lt;style&gt;</span></span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a><span class="co">        /* CSS Variables for Theme */</span></span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a><span class="co">        :root {</span></span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a><span class="co">          --bg-primary: #ffffff;</span></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a><span class="co">          --bg-secondary: #f8f9fa;</span></span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a><span class="co">          --text-primary: #333333;</span></span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a><span class="co">          --text-secondary: #666666;</span></span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a><span class="co">          --border-color: #e0e0e0;</span></span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a><span class="co">          --code-bg: #f5f5f5;</span></span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a><span class="co">          --header-gradient: linear-gradient(135deg, #667eea 0%, #764ba2 100%);</span></span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a><span class="co">          --shadow: rgba(0,0,0,0.1);</span></span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a><span class="co">        [data-theme="dark"] {</span></span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a><span class="co">          --bg-primary: #1a1a1a;</span></span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a><span class="co">          --bg-secondary: #2d2d2d;</span></span>
<span id="cb44-31"><a href="#cb44-31" aria-hidden="true" tabindex="-1"></a><span class="co">          --text-primary: #e0e0e0;</span></span>
<span id="cb44-32"><a href="#cb44-32" aria-hidden="true" tabindex="-1"></a><span class="co">          --text-secondary: #b0b0b0;</span></span>
<span id="cb44-33"><a href="#cb44-33" aria-hidden="true" tabindex="-1"></a><span class="co">          --border-color: #404040;</span></span>
<span id="cb44-34"><a href="#cb44-34" aria-hidden="true" tabindex="-1"></a><span class="co">          --code-bg: #2a2a2a;</span></span>
<span id="cb44-35"><a href="#cb44-35" aria-hidden="true" tabindex="-1"></a><span class="co">          --header-gradient: linear-gradient(135deg, #4a5568 0%, #2d3748 100%);</span></span>
<span id="cb44-36"><a href="#cb44-36" aria-hidden="true" tabindex="-1"></a><span class="co">          --shadow: rgba(0,0,0,0.5);</span></span>
<span id="cb44-37"><a href="#cb44-37" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-38"><a href="#cb44-38" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-39"><a href="#cb44-39" aria-hidden="true" tabindex="-1"></a><span class="co">        /* Apply theme to body and main content */</span></span>
<span id="cb44-40"><a href="#cb44-40" aria-hidden="true" tabindex="-1"></a><span class="co">        body {</span></span>
<span id="cb44-41"><a href="#cb44-41" aria-hidden="true" tabindex="-1"></a><span class="co">          margin-top: 0;</span></span>
<span id="cb44-42"><a href="#cb44-42" aria-hidden="true" tabindex="-1"></a><span class="co">          background-color: var(--bg-primary);</span></span>
<span id="cb44-43"><a href="#cb44-43" aria-hidden="true" tabindex="-1"></a><span class="co">          color: var(--text-primary);</span></span>
<span id="cb44-44"><a href="#cb44-44" aria-hidden="true" tabindex="-1"></a><span class="co">          transition: background-color 0.3s ease, color 0.3s ease;</span></span>
<span id="cb44-45"><a href="#cb44-45" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-46"><a href="#cb44-46" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-47"><a href="#cb44-47" aria-hidden="true" tabindex="-1"></a><span class="co">        /* Theme toggle button */</span></span>
<span id="cb44-48"><a href="#cb44-48" aria-hidden="true" tabindex="-1"></a><span class="co">        .theme-toggle {</span></span>
<span id="cb44-49"><a href="#cb44-49" aria-hidden="true" tabindex="-1"></a><span class="co">          background: rgba(255, 255, 255, 0.2);</span></span>
<span id="cb44-50"><a href="#cb44-50" aria-hidden="true" tabindex="-1"></a><span class="co">          border: 2px solid rgba(255, 255, 255, 0.3);</span></span>
<span id="cb44-51"><a href="#cb44-51" aria-hidden="true" tabindex="-1"></a><span class="co">          color: white;</span></span>
<span id="cb44-52"><a href="#cb44-52" aria-hidden="true" tabindex="-1"></a><span class="co">          padding: 8px 16px;</span></span>
<span id="cb44-53"><a href="#cb44-53" aria-hidden="true" tabindex="-1"></a><span class="co">          border-radius: 20px;</span></span>
<span id="cb44-54"><a href="#cb44-54" aria-hidden="true" tabindex="-1"></a><span class="co">          cursor: pointer;</span></span>
<span id="cb44-55"><a href="#cb44-55" aria-hidden="true" tabindex="-1"></a><span class="co">          font-size: 14px;</span></span>
<span id="cb44-56"><a href="#cb44-56" aria-hidden="true" tabindex="-1"></a><span class="co">          font-weight: 600;</span></span>
<span id="cb44-57"><a href="#cb44-57" aria-hidden="true" tabindex="-1"></a><span class="co">          transition: all 0.3s ease;</span></span>
<span id="cb44-58"><a href="#cb44-58" aria-hidden="true" tabindex="-1"></a><span class="co">          display: inline-flex;</span></span>
<span id="cb44-59"><a href="#cb44-59" aria-hidden="true" tabindex="-1"></a><span class="co">          align-items: center;</span></span>
<span id="cb44-60"><a href="#cb44-60" aria-hidden="true" tabindex="-1"></a><span class="co">          gap: 8px;</span></span>
<span id="cb44-61"><a href="#cb44-61" aria-hidden="true" tabindex="-1"></a><span class="co">          margin-left: 20px;</span></span>
<span id="cb44-62"><a href="#cb44-62" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-63"><a href="#cb44-63" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-64"><a href="#cb44-64" aria-hidden="true" tabindex="-1"></a><span class="co">        .theme-toggle:hover {</span></span>
<span id="cb44-65"><a href="#cb44-65" aria-hidden="true" tabindex="-1"></a><span class="co">          background: rgba(255, 255, 255, 0.3);</span></span>
<span id="cb44-66"><a href="#cb44-66" aria-hidden="true" tabindex="-1"></a><span class="co">          border-color: rgba(255, 255, 255, 0.5);</span></span>
<span id="cb44-67"><a href="#cb44-67" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-68"><a href="#cb44-68" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-69"><a href="#cb44-69" aria-hidden="true" tabindex="-1"></a><span class="co">        .theme-toggle svg {</span></span>
<span id="cb44-70"><a href="#cb44-70" aria-hidden="true" tabindex="-1"></a><span class="co">          width: 18px;</span></span>
<span id="cb44-71"><a href="#cb44-71" aria-hidden="true" tabindex="-1"></a><span class="co">          height: 18px;</span></span>
<span id="cb44-72"><a href="#cb44-72" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-73"><a href="#cb44-73" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-74"><a href="#cb44-74" aria-hidden="true" tabindex="-1"></a><span class="co">        /* Header styles */</span></span>
<span id="cb44-75"><a href="#cb44-75" aria-hidden="true" tabindex="-1"></a><span class="co">        .custom-header {</span></span>
<span id="cb44-76"><a href="#cb44-76" aria-hidden="true" tabindex="-1"></a><span class="co">          background: var(--header-gradient);</span></span>
<span id="cb44-77"><a href="#cb44-77" aria-hidden="true" tabindex="-1"></a><span class="co">          color: white;</span></span>
<span id="cb44-78"><a href="#cb44-78" aria-hidden="true" tabindex="-1"></a><span class="co">          padding: 15px 20px;</span></span>
<span id="cb44-79"><a href="#cb44-79" aria-hidden="true" tabindex="-1"></a><span class="co">          text-align: center;</span></span>
<span id="cb44-80"><a href="#cb44-80" aria-hidden="true" tabindex="-1"></a><span class="co">          box-shadow: 0 2px 10px var(--shadow);</span></span>
<span id="cb44-81"><a href="#cb44-81" aria-hidden="true" tabindex="-1"></a><span class="co">          position: sticky;</span></span>
<span id="cb44-82"><a href="#cb44-82" aria-hidden="true" tabindex="-1"></a><span class="co">          top: 0;</span></span>
<span id="cb44-83"><a href="#cb44-83" aria-hidden="true" tabindex="-1"></a><span class="co">          z-index: 1000;</span></span>
<span id="cb44-84"><a href="#cb44-84" aria-hidden="true" tabindex="-1"></a><span class="co">          margin-bottom: 20px;</span></span>
<span id="cb44-85"><a href="#cb44-85" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-86"><a href="#cb44-86" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-87"><a href="#cb44-87" aria-hidden="true" tabindex="-1"></a><span class="co">        .custom-header .header-content {</span></span>
<span id="cb44-88"><a href="#cb44-88" aria-hidden="true" tabindex="-1"></a><span class="co">          max-width: 1200px;</span></span>
<span id="cb44-89"><a href="#cb44-89" aria-hidden="true" tabindex="-1"></a><span class="co">          margin: 0 auto;</span></span>
<span id="cb44-90"><a href="#cb44-90" aria-hidden="true" tabindex="-1"></a><span class="co">          display: flex;</span></span>
<span id="cb44-91"><a href="#cb44-91" aria-hidden="true" tabindex="-1"></a><span class="co">          justify-content: center;</span></span>
<span id="cb44-92"><a href="#cb44-92" aria-hidden="true" tabindex="-1"></a><span class="co">          align-items: center;</span></span>
<span id="cb44-93"><a href="#cb44-93" aria-hidden="true" tabindex="-1"></a><span class="co">          flex-wrap: wrap;</span></span>
<span id="cb44-94"><a href="#cb44-94" aria-hidden="true" tabindex="-1"></a><span class="co">          gap: 15px;</span></span>
<span id="cb44-95"><a href="#cb44-95" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-96"><a href="#cb44-96" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-97"><a href="#cb44-97" aria-hidden="true" tabindex="-1"></a><span class="co">        .custom-header a {</span></span>
<span id="cb44-98"><a href="#cb44-98" aria-hidden="true" tabindex="-1"></a><span class="co">          color: white;</span></span>
<span id="cb44-99"><a href="#cb44-99" aria-hidden="true" tabindex="-1"></a><span class="co">          text-decoration: none;</span></span>
<span id="cb44-100"><a href="#cb44-100" aria-hidden="true" tabindex="-1"></a><span class="co">          font-weight: 600;</span></span>
<span id="cb44-101"><a href="#cb44-101" aria-hidden="true" tabindex="-1"></a><span class="co">          margin: 0 15px;</span></span>
<span id="cb44-102"><a href="#cb44-102" aria-hidden="true" tabindex="-1"></a><span class="co">          transition: opacity 0.3s ease;</span></span>
<span id="cb44-103"><a href="#cb44-103" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-104"><a href="#cb44-104" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-105"><a href="#cb44-105" aria-hidden="true" tabindex="-1"></a><span class="co">        .custom-header a:hover {</span></span>
<span id="cb44-106"><a href="#cb44-106" aria-hidden="true" tabindex="-1"></a><span class="co">          opacity: 0.8;</span></span>
<span id="cb44-107"><a href="#cb44-107" aria-hidden="true" tabindex="-1"></a><span class="co">          text-decoration: underline;</span></span>
<span id="cb44-108"><a href="#cb44-108" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-109"><a href="#cb44-109" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-110"><a href="#cb44-110" aria-hidden="true" tabindex="-1"></a><span class="co">        .custom-header .github-link {</span></span>
<span id="cb44-111"><a href="#cb44-111" aria-hidden="true" tabindex="-1"></a><span class="co">          display: inline-flex;</span></span>
<span id="cb44-112"><a href="#cb44-112" aria-hidden="true" tabindex="-1"></a><span class="co">          align-items: center;</span></span>
<span id="cb44-113"><a href="#cb44-113" aria-hidden="true" tabindex="-1"></a><span class="co">          gap: 8px;</span></span>
<span id="cb44-114"><a href="#cb44-114" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-115"><a href="#cb44-115" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-116"><a href="#cb44-116" aria-hidden="true" tabindex="-1"></a><span class="co">        /* Footer styles */</span></span>
<span id="cb44-117"><a href="#cb44-117" aria-hidden="true" tabindex="-1"></a><span class="co">        .custom-footer {</span></span>
<span id="cb44-118"><a href="#cb44-118" aria-hidden="true" tabindex="-1"></a><span class="co">          background: var(--header-gradient);</span></span>
<span id="cb44-119"><a href="#cb44-119" aria-hidden="true" tabindex="-1"></a><span class="co">          color: white;</span></span>
<span id="cb44-120"><a href="#cb44-120" aria-hidden="true" tabindex="-1"></a><span class="co">          padding: 25px 20px;</span></span>
<span id="cb44-121"><a href="#cb44-121" aria-hidden="true" tabindex="-1"></a><span class="co">          text-align: center;</span></span>
<span id="cb44-122"><a href="#cb44-122" aria-hidden="true" tabindex="-1"></a><span class="co">          margin-top: 50px;</span></span>
<span id="cb44-123"><a href="#cb44-123" aria-hidden="true" tabindex="-1"></a><span class="co">          box-shadow: 0 -2px 10px var(--shadow);</span></span>
<span id="cb44-124"><a href="#cb44-124" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-125"><a href="#cb44-125" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-126"><a href="#cb44-126" aria-hidden="true" tabindex="-1"></a><span class="co">        .custom-footer a {</span></span>
<span id="cb44-127"><a href="#cb44-127" aria-hidden="true" tabindex="-1"></a><span class="co">          color: white;</span></span>
<span id="cb44-128"><a href="#cb44-128" aria-hidden="true" tabindex="-1"></a><span class="co">          text-decoration: none;</span></span>
<span id="cb44-129"><a href="#cb44-129" aria-hidden="true" tabindex="-1"></a><span class="co">          font-weight: 600;</span></span>
<span id="cb44-130"><a href="#cb44-130" aria-hidden="true" tabindex="-1"></a><span class="co">          margin: 0 15px;</span></span>
<span id="cb44-131"><a href="#cb44-131" aria-hidden="true" tabindex="-1"></a><span class="co">          transition: opacity 0.3s ease;</span></span>
<span id="cb44-132"><a href="#cb44-132" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-133"><a href="#cb44-133" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-134"><a href="#cb44-134" aria-hidden="true" tabindex="-1"></a><span class="co">        .custom-footer a:hover {</span></span>
<span id="cb44-135"><a href="#cb44-135" aria-hidden="true" tabindex="-1"></a><span class="co">          opacity: 0.8;</span></span>
<span id="cb44-136"><a href="#cb44-136" aria-hidden="true" tabindex="-1"></a><span class="co">          text-decoration: underline;</span></span>
<span id="cb44-137"><a href="#cb44-137" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-138"><a href="#cb44-138" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-139"><a href="#cb44-139" aria-hidden="true" tabindex="-1"></a><span class="co">        .custom-footer .footer-content {</span></span>
<span id="cb44-140"><a href="#cb44-140" aria-hidden="true" tabindex="-1"></a><span class="co">          max-width: 1200px;</span></span>
<span id="cb44-141"><a href="#cb44-141" aria-hidden="true" tabindex="-1"></a><span class="co">          margin: 0 auto;</span></span>
<span id="cb44-142"><a href="#cb44-142" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-143"><a href="#cb44-143" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-144"><a href="#cb44-144" aria-hidden="true" tabindex="-1"></a><span class="co">        .custom-footer .footer-links {</span></span>
<span id="cb44-145"><a href="#cb44-145" aria-hidden="true" tabindex="-1"></a><span class="co">          margin: 15px 0;</span></span>
<span id="cb44-146"><a href="#cb44-146" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-147"><a href="#cb44-147" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-148"><a href="#cb44-148" aria-hidden="true" tabindex="-1"></a><span class="co">        /* Dark theme adjustments for Quarto content */</span></span>
<span id="cb44-149"><a href="#cb44-149" aria-hidden="true" tabindex="-1"></a><span class="co">        [data-theme="dark"] .quarto-title-block,</span></span>
<span id="cb44-150"><a href="#cb44-150" aria-hidden="true" tabindex="-1"></a><span class="co">        [data-theme="dark"] .quarto-title {</span></span>
<span id="cb44-151"><a href="#cb44-151" aria-hidden="true" tabindex="-1"></a><span class="co">          color: var(--text-primary);</span></span>
<span id="cb44-152"><a href="#cb44-152" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-153"><a href="#cb44-153" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-154"><a href="#cb44-154" aria-hidden="true" tabindex="-1"></a><span class="co">        [data-theme="dark"] pre,</span></span>
<span id="cb44-155"><a href="#cb44-155" aria-hidden="true" tabindex="-1"></a><span class="co">        [data-theme="dark"] code {</span></span>
<span id="cb44-156"><a href="#cb44-156" aria-hidden="true" tabindex="-1"></a><span class="co">          background-color: var(--code-bg);</span></span>
<span id="cb44-157"><a href="#cb44-157" aria-hidden="true" tabindex="-1"></a><span class="co">          color: var(--text-primary);</span></span>
<span id="cb44-158"><a href="#cb44-158" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-159"><a href="#cb44-159" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-160"><a href="#cb44-160" aria-hidden="true" tabindex="-1"></a><span class="co">        [data-theme="dark"] .cell-output {</span></span>
<span id="cb44-161"><a href="#cb44-161" aria-hidden="true" tabindex="-1"></a><span class="co">          background-color: var(--bg-secondary);</span></span>
<span id="cb44-162"><a href="#cb44-162" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-163"><a href="#cb44-163" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-164"><a href="#cb44-164" aria-hidden="true" tabindex="-1"></a><span class="co">        [data-theme="dark"] table {</span></span>
<span id="cb44-165"><a href="#cb44-165" aria-hidden="true" tabindex="-1"></a><span class="co">          border-color: var(--border-color);</span></span>
<span id="cb44-166"><a href="#cb44-166" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-167"><a href="#cb44-167" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-168"><a href="#cb44-168" aria-hidden="true" tabindex="-1"></a><span class="co">        [data-theme="dark"] .table {</span></span>
<span id="cb44-169"><a href="#cb44-169" aria-hidden="true" tabindex="-1"></a><span class="co">          color: var(--text-primary);</span></span>
<span id="cb44-170"><a href="#cb44-170" aria-hidden="true" tabindex="-1"></a><span class="co">        }</span></span>
<span id="cb44-171"><a href="#cb44-171" aria-hidden="true" tabindex="-1"></a><span class="co">      &lt;/style&gt;</span></span>
<span id="cb44-172"><a href="#cb44-172" aria-hidden="true" tabindex="-1"></a><span class="co">      &lt;div class="custom-header"&gt;</span></span>
<span id="cb44-173"><a href="#cb44-173" aria-hidden="true" tabindex="-1"></a><span class="co">        &lt;div class="header-content"&gt;</span></span>
<span id="cb44-174"><a href="#cb44-174" aria-hidden="true" tabindex="-1"></a><span class="co">          &lt;a href="https://github.com/Exios66" class="github-link" target="_blank" rel="noopener"&gt;</span></span>
<span id="cb44-175"><a href="#cb44-175" aria-hidden="true" tabindex="-1"></a><span class="co">            &lt;svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor" style="vertical-align: middle;"&gt;</span></span>
<span id="cb44-176"><a href="#cb44-176" aria-hidden="true" tabindex="-1"></a><span class="co">              &lt;path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/&gt;</span></span>
<span id="cb44-177"><a href="#cb44-177" aria-hidden="true" tabindex="-1"></a><span class="co">            &lt;/svg&gt;</span></span>
<span id="cb44-178"><a href="#cb44-178" aria-hidden="true" tabindex="-1"></a><span class="co">            GitHub: Exios66</span></span>
<span id="cb44-179"><a href="#cb44-179" aria-hidden="true" tabindex="-1"></a><span class="co">          &lt;/a&gt;</span></span>
<span id="cb44-180"><a href="#cb44-180" aria-hidden="true" tabindex="-1"></a><span class="co">          &lt;button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme"&gt;</span></span>
<span id="cb44-181"><a href="#cb44-181" aria-hidden="true" tabindex="-1"></a><span class="co">            &lt;svg id="theme-icon" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"&gt;</span></span>
<span id="cb44-182"><a href="#cb44-182" aria-hidden="true" tabindex="-1"></a><span class="co">              &lt;circle cx="12" cy="12" r="5"&gt;&lt;/circle&gt;</span></span>
<span id="cb44-183"><a href="#cb44-183" aria-hidden="true" tabindex="-1"></a><span class="co">              &lt;line x1="12" y1="1" x2="12" y2="3"&gt;&lt;/line&gt;</span></span>
<span id="cb44-184"><a href="#cb44-184" aria-hidden="true" tabindex="-1"></a><span class="co">              &lt;line x1="12" y1="21" x2="12" y2="23"&gt;&lt;/line&gt;</span></span>
<span id="cb44-185"><a href="#cb44-185" aria-hidden="true" tabindex="-1"></a><span class="co">              &lt;line x1="4.22" y1="4.22" x2="5.64" y2="5.64"&gt;&lt;/line&gt;</span></span>
<span id="cb44-186"><a href="#cb44-186" aria-hidden="true" tabindex="-1"></a><span class="co">              &lt;line x1="18.36" y1="18.36" x2="19.78" y2="19.78"&gt;&lt;/line&gt;</span></span>
<span id="cb44-187"><a href="#cb44-187" aria-hidden="true" tabindex="-1"></a><span class="co">              &lt;line x1="1" y1="12" x2="3" y2="12"&gt;&lt;/line&gt;</span></span>
<span id="cb44-188"><a href="#cb44-188" aria-hidden="true" tabindex="-1"></a><span class="co">              &lt;line x1="21" y1="12" x2="23" y2="12"&gt;&lt;/line&gt;</span></span>
<span id="cb44-189"><a href="#cb44-189" aria-hidden="true" tabindex="-1"></a><span class="co">              &lt;line x1="4.22" y1="19.78" x2="5.64" y2="18.36"&gt;&lt;/line&gt;</span></span>
<span id="cb44-190"><a href="#cb44-190" aria-hidden="true" tabindex="-1"></a><span class="co">              &lt;line x1="18.36" y1="5.64" x2="19.78" y2="4.22"&gt;&lt;/line&gt;</span></span>
<span id="cb44-191"><a href="#cb44-191" aria-hidden="true" tabindex="-1"></a><span class="co">            &lt;/svg&gt;</span></span>
<span id="cb44-192"><a href="#cb44-192" aria-hidden="true" tabindex="-1"></a><span class="co">            &lt;span id="theme-text"&gt;Dark&lt;/span&gt;</span></span>
<span id="cb44-193"><a href="#cb44-193" aria-hidden="true" tabindex="-1"></a><span class="co">          &lt;/button&gt;</span></span>
<span id="cb44-194"><a href="#cb44-194" aria-hidden="true" tabindex="-1"></a><span class="co">        &lt;/div&gt;</span></span>
<span id="cb44-195"><a href="#cb44-195" aria-hidden="true" tabindex="-1"></a><span class="co">      &lt;/div&gt;</span></span>
<span id="cb44-196"><a href="#cb44-196" aria-hidden="true" tabindex="-1"></a><span class="co">      &lt;script&gt;</span></span>
<span id="cb44-197"><a href="#cb44-197" aria-hidden="true" tabindex="-1"></a><span class="co">        (function() {</span></span>
<span id="cb44-198"><a href="#cb44-198" aria-hidden="true" tabindex="-1"></a><span class="co">          // Get theme from localStorage or default to light</span></span>
<span id="cb44-199"><a href="#cb44-199" aria-hidden="true" tabindex="-1"></a><span class="co">          const currentTheme = localStorage.getItem('theme') || 'light';</span></span>
<span id="cb44-200"><a href="#cb44-200" aria-hidden="true" tabindex="-1"></a><span class="co">          const html = document.documentElement;</span></span>
<span id="cb44-201"><a href="#cb44-201" aria-hidden="true" tabindex="-1"></a><span class="co">          </span></span>
<span id="cb44-202"><a href="#cb44-202" aria-hidden="true" tabindex="-1"></a><span class="co">          // Set initial theme</span></span>
<span id="cb44-203"><a href="#cb44-203" aria-hidden="true" tabindex="-1"></a><span class="co">          html.setAttribute('data-theme', currentTheme);</span></span>
<span id="cb44-204"><a href="#cb44-204" aria-hidden="true" tabindex="-1"></a><span class="co">          </span></span>
<span id="cb44-205"><a href="#cb44-205" aria-hidden="true" tabindex="-1"></a><span class="co">          // Theme toggle function</span></span>
<span id="cb44-206"><a href="#cb44-206" aria-hidden="true" tabindex="-1"></a><span class="co">          function toggleTheme() {</span></span>
<span id="cb44-207"><a href="#cb44-207" aria-hidden="true" tabindex="-1"></a><span class="co">            const currentTheme = html.getAttribute('data-theme');</span></span>
<span id="cb44-208"><a href="#cb44-208" aria-hidden="true" tabindex="-1"></a><span class="co">            const newTheme = currentTheme === 'light' ? 'dark' : 'light';</span></span>
<span id="cb44-209"><a href="#cb44-209" aria-hidden="true" tabindex="-1"></a><span class="co">            </span></span>
<span id="cb44-210"><a href="#cb44-210" aria-hidden="true" tabindex="-1"></a><span class="co">            html.setAttribute('data-theme', newTheme);</span></span>
<span id="cb44-211"><a href="#cb44-211" aria-hidden="true" tabindex="-1"></a><span class="co">            localStorage.setItem('theme', newTheme);</span></span>
<span id="cb44-212"><a href="#cb44-212" aria-hidden="true" tabindex="-1"></a><span class="co">            </span></span>
<span id="cb44-213"><a href="#cb44-213" aria-hidden="true" tabindex="-1"></a><span class="co">            // Update button text and icon</span></span>
<span id="cb44-214"><a href="#cb44-214" aria-hidden="true" tabindex="-1"></a><span class="co">            updateThemeButton(newTheme);</span></span>
<span id="cb44-215"><a href="#cb44-215" aria-hidden="true" tabindex="-1"></a><span class="co">          }</span></span>
<span id="cb44-216"><a href="#cb44-216" aria-hidden="true" tabindex="-1"></a><span class="co">          </span></span>
<span id="cb44-217"><a href="#cb44-217" aria-hidden="true" tabindex="-1"></a><span class="co">          // Update button appearance</span></span>
<span id="cb44-218"><a href="#cb44-218" aria-hidden="true" tabindex="-1"></a><span class="co">          function updateThemeButton(theme) {</span></span>
<span id="cb44-219"><a href="#cb44-219" aria-hidden="true" tabindex="-1"></a><span class="co">            const themeText = document.getElementById('theme-text');</span></span>
<span id="cb44-220"><a href="#cb44-220" aria-hidden="true" tabindex="-1"></a><span class="co">            const themeIcon = document.getElementById('theme-icon');</span></span>
<span id="cb44-221"><a href="#cb44-221" aria-hidden="true" tabindex="-1"></a><span class="co">            </span></span>
<span id="cb44-222"><a href="#cb44-222" aria-hidden="true" tabindex="-1"></a><span class="co">            if (theme === 'dark') {</span></span>
<span id="cb44-223"><a href="#cb44-223" aria-hidden="true" tabindex="-1"></a><span class="co">              themeText.textContent = 'Light';</span></span>
<span id="cb44-224"><a href="#cb44-224" aria-hidden="true" tabindex="-1"></a><span class="co">              // Moon icon for dark mode (switch to light)</span></span>
<span id="cb44-225"><a href="#cb44-225" aria-hidden="true" tabindex="-1"></a><span class="co">              themeIcon.innerHTML = '&lt;path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"&gt;&lt;/path&gt;';</span></span>
<span id="cb44-226"><a href="#cb44-226" aria-hidden="true" tabindex="-1"></a><span class="co">            } else {</span></span>
<span id="cb44-227"><a href="#cb44-227" aria-hidden="true" tabindex="-1"></a><span class="co">              themeText.textContent = 'Dark';</span></span>
<span id="cb44-228"><a href="#cb44-228" aria-hidden="true" tabindex="-1"></a><span class="co">              // Sun icon for light mode (switch to dark)</span></span>
<span id="cb44-229"><a href="#cb44-229" aria-hidden="true" tabindex="-1"></a><span class="co">              themeIcon.innerHTML = '&lt;circle cx="12" cy="12" r="5"&gt;&lt;/circle&gt;&lt;line x1="12" y1="1" x2="12" y2="3"&gt;&lt;/line&gt;&lt;line x1="12" y1="21" x2="12" y2="23"&gt;&lt;/line&gt;&lt;line x1="4.22" y1="4.22" x2="5.64" y2="5.64"&gt;&lt;/line&gt;&lt;line x1="18.36" y1="18.36" x2="19.78" y2="19.78"&gt;&lt;/line&gt;&lt;line x1="1" y1="12" x2="3" y2="12"&gt;&lt;/line&gt;&lt;line x1="21" y1="12" x2="23" y2="12"&gt;&lt;/line&gt;&lt;line x1="4.22" y1="19.78" x2="5.64" y2="18.36"&gt;&lt;/line&gt;&lt;line x1="18.36" y1="5.64" x2="19.78" y2="4.22"&gt;&lt;/line&gt;';</span></span>
<span id="cb44-230"><a href="#cb44-230" aria-hidden="true" tabindex="-1"></a><span class="co">            }</span></span>
<span id="cb44-231"><a href="#cb44-231" aria-hidden="true" tabindex="-1"></a><span class="co">          }</span></span>
<span id="cb44-232"><a href="#cb44-232" aria-hidden="true" tabindex="-1"></a><span class="co">          </span></span>
<span id="cb44-233"><a href="#cb44-233" aria-hidden="true" tabindex="-1"></a><span class="co">          // Initialize button state</span></span>
<span id="cb44-234"><a href="#cb44-234" aria-hidden="true" tabindex="-1"></a><span class="co">          updateThemeButton(currentTheme);</span></span>
<span id="cb44-235"><a href="#cb44-235" aria-hidden="true" tabindex="-1"></a><span class="co">          </span></span>
<span id="cb44-236"><a href="#cb44-236" aria-hidden="true" tabindex="-1"></a><span class="co">          // Add event listener</span></span>
<span id="cb44-237"><a href="#cb44-237" aria-hidden="true" tabindex="-1"></a><span class="co">          const themeToggle = document.getElementById('theme-toggle');</span></span>
<span id="cb44-238"><a href="#cb44-238" aria-hidden="true" tabindex="-1"></a><span class="co">          if (themeToggle) {</span></span>
<span id="cb44-239"><a href="#cb44-239" aria-hidden="true" tabindex="-1"></a><span class="co">            themeToggle.addEventListener('click', toggleTheme);</span></span>
<span id="cb44-240"><a href="#cb44-240" aria-hidden="true" tabindex="-1"></a><span class="co">          }</span></span>
<span id="cb44-241"><a href="#cb44-241" aria-hidden="true" tabindex="-1"></a><span class="co">        })();</span></span>
<span id="cb44-242"><a href="#cb44-242" aria-hidden="true" tabindex="-1"></a><span class="co">      &lt;/script&gt;</span></span>
<span id="cb44-243"><a href="#cb44-243" aria-hidden="true" tabindex="-1"></a><span class="co">    include-after-body: |</span></span>
<span id="cb44-244"><a href="#cb44-244" aria-hidden="true" tabindex="-1"></a><span class="co">      &lt;div class="custom-footer"&gt;</span></span>
<span id="cb44-245"><a href="#cb44-245" aria-hidden="true" tabindex="-1"></a><span class="co">        &lt;div class="footer-content"&gt;</span></span>
<span id="cb44-246"><a href="#cb44-246" aria-hidden="true" tabindex="-1"></a><span class="co">          &lt;p style="margin: 0; font-size: 1.1em; font-weight: 600;"&gt;Random Forest Algorithms: Applications to Large-Scale Datasets&lt;/p&gt;</span></span>
<span id="cb44-247"><a href="#cb44-247" aria-hidden="true" tabindex="-1"></a><span class="co">          &lt;div class="footer-links"&gt;</span></span>
<span id="cb44-248"><a href="#cb44-248" aria-hidden="true" tabindex="-1"></a><span class="co">            &lt;a href="https://github.com/Exios66" target="_blank" rel="noopener"&gt;</span></span>
<span id="cb44-249"><a href="#cb44-249" aria-hidden="true" tabindex="-1"></a><span class="co">              &lt;svg width="18" height="18" viewBox="0 0 24 24" fill="currentColor" style="vertical-align: middle; margin-right: 5px;"&gt;</span></span>
<span id="cb44-250"><a href="#cb44-250" aria-hidden="true" tabindex="-1"></a><span class="co">                &lt;path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/&gt;</span></span>
<span id="cb44-251"><a href="#cb44-251" aria-hidden="true" tabindex="-1"></a><span class="co">              &lt;/svg&gt;</span></span>
<span id="cb44-252"><a href="#cb44-252" aria-hidden="true" tabindex="-1"></a><span class="co">              Visit GitHub Profile: Exios66</span></span>
<span id="cb44-253"><a href="#cb44-253" aria-hidden="true" tabindex="-1"></a><span class="co">            &lt;/a&gt;</span></span>
<span id="cb44-254"><a href="#cb44-254" aria-hidden="true" tabindex="-1"></a><span class="co">          &lt;/div&gt;</span></span>
<span id="cb44-255"><a href="#cb44-255" aria-hidden="true" tabindex="-1"></a><span class="co">          &lt;p style="margin: 15px 0 0 0; font-size: 0.9em; opacity: 0.9;"&gt;© 2024 Jack J. Burleson | Generated with Quarto&lt;/p&gt;</span></span>
<span id="cb44-256"><a href="#cb44-256" aria-hidden="true" tabindex="-1"></a><span class="co">        &lt;/div&gt;</span></span>
<span id="cb44-257"><a href="#cb44-257" aria-hidden="true" tabindex="-1"></a><span class="co">      &lt;/div&gt;</span></span>
<span id="cb44-258"><a href="#cb44-258" aria-hidden="true" tabindex="-1"></a><span class="an">editor:</span><span class="co"> visual</span></span>
<span id="cb44-259"><a href="#cb44-259" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb44-260"><a href="#cb44-260" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb44-261"><a href="#cb44-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-262"><a href="#cb44-262" aria-hidden="true" tabindex="-1"></a><span class="fu">## Abstract</span></span>
<span id="cb44-263"><a href="#cb44-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-264"><a href="#cb44-264" aria-hidden="true" tabindex="-1"></a>Random Forest algorithms represent one of the most robust and widely-applied machine learning techniques for both classification and regression tasks. This document provides a comprehensive examination of Random Forest methodology, its theoretical foundations, practical implementation strategies, and applications to large-scale datasets. Through empirical demonstrations and code examples, we illustrate the effectiveness of ensemble learning approaches in handling complex, high-dimensional data structures while maintaining interpretability and computational efficiency.</span>
<span id="cb44-265"><a href="#cb44-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-266"><a href="#cb44-266" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb44-267"><a href="#cb44-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-268"><a href="#cb44-268" aria-hidden="true" tabindex="-1"></a>Random Forest, introduced by Breiman (2001), is an ensemble learning method that constructs multiple decision trees during training and outputs the mode of classes (classification) or mean prediction (regression) of the individual trees. The algorithm's strength lies in its ability to reduce overfitting through the aggregation of diverse tree predictions while maintaining high predictive accuracy across diverse domains.</span>
<span id="cb44-269"><a href="#cb44-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-270"><a href="#cb44-270" aria-hidden="true" tabindex="-1"></a><span class="fu">### Key Advantages</span></span>
<span id="cb44-271"><a href="#cb44-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-272"><a href="#cb44-272" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Robustness to Overfitting**: Through bootstrap aggregation and random feature selection</span>
<span id="cb44-273"><a href="#cb44-273" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Handling of High-Dimensional Data**: Effective feature selection mechanisms</span>
<span id="cb44-274"><a href="#cb44-274" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Non-parametric Nature**: No assumptions about data distribution</span>
<span id="cb44-275"><a href="#cb44-275" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Feature Importance**: Built-in mechanisms for variable importance assessment</span>
<span id="cb44-276"><a href="#cb44-276" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Scalability**: Efficient parallelization capabilities</span>
<span id="cb44-277"><a href="#cb44-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-278"><a href="#cb44-278" aria-hidden="true" tabindex="-1"></a><span class="fu">## Theoretical Foundations</span></span>
<span id="cb44-279"><a href="#cb44-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-280"><a href="#cb44-280" aria-hidden="true" tabindex="-1"></a><span class="fu">### Bootstrap Aggregation (Bagging)</span></span>
<span id="cb44-281"><a href="#cb44-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-282"><a href="#cb44-282" aria-hidden="true" tabindex="-1"></a>Random Forest employs bootstrap aggregation, where each tree is trained on a random subset of the training data sampled with replacement. This process reduces variance and improves generalization performance.</span>
<span id="cb44-283"><a href="#cb44-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-284"><a href="#cb44-284" aria-hidden="true" tabindex="-1"></a><span class="fu">### Random Feature Selection</span></span>
<span id="cb44-285"><a href="#cb44-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-286"><a href="#cb44-286" aria-hidden="true" tabindex="-1"></a>At each node split, the algorithm considers only a random subset of features, typically $\sqrt{p}$ for classification and $p/3$ for regression, where $p$ is the total number of features. This decorrelates the trees and enhances model diversity.</span>
<span id="cb44-287"><a href="#cb44-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-288"><a href="#cb44-288" aria-hidden="true" tabindex="-1"></a><span class="fu">### Mathematical Formulation</span></span>
<span id="cb44-289"><a href="#cb44-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-290"><a href="#cb44-290" aria-hidden="true" tabindex="-1"></a>For a Random Forest with $B$ trees, the prediction for a new observation $\mathbf{x}$ is:</span>
<span id="cb44-291"><a href="#cb44-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-292"><a href="#cb44-292" aria-hidden="true" tabindex="-1"></a>$$\hat{f}_{RF}(\mathbf{x}) = \frac{1}{B}\sum_{b=1}^{B} T_b(\mathbf{x})$$</span>
<span id="cb44-293"><a href="#cb44-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-294"><a href="#cb44-294" aria-hidden="true" tabindex="-1"></a>where $T_b(\mathbf{x})$ represents the prediction from the $b$-th tree.</span>
<span id="cb44-295"><a href="#cb44-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-296"><a href="#cb44-296" aria-hidden="true" tabindex="-1"></a><span class="fu">## Implementation: Core Components</span></span>
<span id="cb44-297"><a href="#cb44-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-298"><a href="#cb44-298" aria-hidden="true" tabindex="-1"></a><span class="fu">### Essential Libraries and Setup</span></span>
<span id="cb44-299"><a href="#cb44-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-302"><a href="#cb44-302" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-303"><a href="#cb44-303" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: setup</span></span>
<span id="cb44-304"><a href="#cb44-304" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: true</span></span>
<span id="cb44-305"><a href="#cb44-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-306"><a href="#cb44-306" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb44-307"><a href="#cb44-307" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb44-308"><a href="#cb44-308" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb44-309"><a href="#cb44-309" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb44-310"><a href="#cb44-310" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, RandomForestRegressor</span>
<span id="cb44-311"><a href="#cb44-311" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, cross_val_score, GridSearchCV</span>
<span id="cb44-312"><a href="#cb44-312" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (accuracy_score, classification_report, </span>
<span id="cb44-313"><a href="#cb44-313" aria-hidden="true" tabindex="-1"></a>                            confusion_matrix, mean_squared_error, r2_score)</span>
<span id="cb44-314"><a href="#cb44-314" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification, make_regression</span>
<span id="cb44-315"><a href="#cb44-315" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb44-316"><a href="#cb44-316" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb44-317"><a href="#cb44-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-318"><a href="#cb44-318" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seed for reproducibility</span></span>
<span id="cb44-319"><a href="#cb44-319" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb44-320"><a href="#cb44-320" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-321"><a href="#cb44-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-322"><a href="#cb44-322" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data Preparation for Large Datasets</span></span>
<span id="cb44-323"><a href="#cb44-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-326"><a href="#cb44-326" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-327"><a href="#cb44-327" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: data-prep</span></span>
<span id="cb44-328"><a href="#cb44-328" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-329"><a href="#cb44-329" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-330"><a href="#cb44-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-331"><a href="#cb44-331" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prepare_large_dataset(n_samples<span class="op">=</span><span class="dv">10000</span>, n_features<span class="op">=</span><span class="dv">50</span>, n_informative<span class="op">=</span><span class="dv">20</span>):</span>
<span id="cb44-332"><a href="#cb44-332" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb44-333"><a href="#cb44-333" aria-hidden="true" tabindex="-1"></a><span class="co">    Generate a synthetic large-scale dataset for demonstration.</span></span>
<span id="cb44-334"><a href="#cb44-334" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb44-335"><a href="#cb44-335" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb44-336"><a href="#cb44-336" aria-hidden="true" tabindex="-1"></a><span class="co">    -----------</span></span>
<span id="cb44-337"><a href="#cb44-337" aria-hidden="true" tabindex="-1"></a><span class="co">    n_samples : int</span></span>
<span id="cb44-338"><a href="#cb44-338" aria-hidden="true" tabindex="-1"></a><span class="co">        Number of samples</span></span>
<span id="cb44-339"><a href="#cb44-339" aria-hidden="true" tabindex="-1"></a><span class="co">    n_features : int</span></span>
<span id="cb44-340"><a href="#cb44-340" aria-hidden="true" tabindex="-1"></a><span class="co">        Total number of features</span></span>
<span id="cb44-341"><a href="#cb44-341" aria-hidden="true" tabindex="-1"></a><span class="co">    n_informative : int</span></span>
<span id="cb44-342"><a href="#cb44-342" aria-hidden="true" tabindex="-1"></a><span class="co">        Number of informative features</span></span>
<span id="cb44-343"><a href="#cb44-343" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-344"><a href="#cb44-344" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb44-345"><a href="#cb44-345" aria-hidden="true" tabindex="-1"></a><span class="co">    --------</span></span>
<span id="cb44-346"><a href="#cb44-346" aria-hidden="true" tabindex="-1"></a><span class="co">    X, y : tuple</span></span>
<span id="cb44-347"><a href="#cb44-347" aria-hidden="true" tabindex="-1"></a><span class="co">        Feature matrix and target vector</span></span>
<span id="cb44-348"><a href="#cb44-348" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb44-349"><a href="#cb44-349" aria-hidden="true" tabindex="-1"></a>    X, y <span class="op">=</span> make_classification(</span>
<span id="cb44-350"><a href="#cb44-350" aria-hidden="true" tabindex="-1"></a>        n_samples<span class="op">=</span>n_samples,</span>
<span id="cb44-351"><a href="#cb44-351" aria-hidden="true" tabindex="-1"></a>        n_features<span class="op">=</span>n_features,</span>
<span id="cb44-352"><a href="#cb44-352" aria-hidden="true" tabindex="-1"></a>        n_informative<span class="op">=</span>n_informative,</span>
<span id="cb44-353"><a href="#cb44-353" aria-hidden="true" tabindex="-1"></a>        n_redundant<span class="op">=</span>n_features <span class="op">-</span> n_informative,</span>
<span id="cb44-354"><a href="#cb44-354" aria-hidden="true" tabindex="-1"></a>        n_clusters_per_class<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb44-355"><a href="#cb44-355" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb44-356"><a href="#cb44-356" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb44-357"><a href="#cb44-357" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X, y</span>
<span id="cb44-358"><a href="#cb44-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-359"><a href="#cb44-359" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate large dataset</span></span>
<span id="cb44-360"><a href="#cb44-360" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> prepare_large_dataset(n_samples<span class="op">=</span><span class="dv">50000</span>, n_features<span class="op">=</span><span class="dv">100</span>, n_informative<span class="op">=</span><span class="dv">40</span>)</span>
<span id="cb44-361"><a href="#cb44-361" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dataset shape: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-362"><a href="#cb44-362" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Target distribution: </span><span class="sc">{</span>np<span class="sc">.</span>bincount(y)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-363"><a href="#cb44-363" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-364"><a href="#cb44-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-365"><a href="#cb44-365" aria-hidden="true" tabindex="-1"></a><span class="fu">### Random Forest Classifier: Critical Implementation</span></span>
<span id="cb44-366"><a href="#cb44-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-369"><a href="#cb44-369" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-370"><a href="#cb44-370" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: rf-classifier</span></span>
<span id="cb44-371"><a href="#cb44-371" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-372"><a href="#cb44-372" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-373"><a href="#cb44-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-374"><a href="#cb44-374" aria-hidden="true" tabindex="-1"></a><span class="co"># Split data into training and testing sets</span></span>
<span id="cb44-375"><a href="#cb44-375" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb44-376"><a href="#cb44-376" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y</span>
<span id="cb44-377"><a href="#cb44-377" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-378"><a href="#cb44-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-379"><a href="#cb44-379" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize Random Forest with optimized hyperparameters</span></span>
<span id="cb44-380"><a href="#cb44-380" aria-hidden="true" tabindex="-1"></a>rf_classifier <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb44-381"><a href="#cb44-381" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,           <span class="co"># Number of trees</span></span>
<span id="cb44-382"><a href="#cb44-382" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="va">None</span>,              <span class="co"># Maximum depth (None = unlimited)</span></span>
<span id="cb44-383"><a href="#cb44-383" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">2</span>,         <span class="co"># Minimum samples to split node</span></span>
<span id="cb44-384"><a href="#cb44-384" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">1</span>,          <span class="co"># Minimum samples in leaf node</span></span>
<span id="cb44-385"><a href="#cb44-385" aria-hidden="true" tabindex="-1"></a>    max_features<span class="op">=</span><span class="st">'sqrt'</span>,         <span class="co"># Number of features to consider (sqrt for classification)</span></span>
<span id="cb44-386"><a href="#cb44-386" aria-hidden="true" tabindex="-1"></a>    bootstrap<span class="op">=</span><span class="va">True</span>,              <span class="co"># Bootstrap sampling</span></span>
<span id="cb44-387"><a href="#cb44-387" aria-hidden="true" tabindex="-1"></a>    oob_score<span class="op">=</span><span class="va">True</span>,              <span class="co"># Out-of-bag score</span></span>
<span id="cb44-388"><a href="#cb44-388" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb44-389"><a href="#cb44-389" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>                    <span class="co"># Use all available cores</span></span>
<span id="cb44-390"><a href="#cb44-390" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-391"><a href="#cb44-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-392"><a href="#cb44-392" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb44-393"><a href="#cb44-393" aria-hidden="true" tabindex="-1"></a>rf_classifier.fit(X_train, y_train)</span>
<span id="cb44-394"><a href="#cb44-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-395"><a href="#cb44-395" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate performance</span></span>
<span id="cb44-396"><a href="#cb44-396" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> rf_classifier.predict(X_test)</span>
<span id="cb44-397"><a href="#cb44-397" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb44-398"><a href="#cb44-398" aria-hidden="true" tabindex="-1"></a>oob_score <span class="op">=</span> rf_classifier.oob_score_</span>
<span id="cb44-399"><a href="#cb44-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-400"><a href="#cb44-400" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb44-401"><a href="#cb44-401" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Out-of-Bag Score: </span><span class="sc">{</span>oob_score<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb44-402"><a href="#cb44-402" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-403"><a href="#cb44-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-404"><a href="#cb44-404" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feature Importance Analysis</span></span>
<span id="cb44-405"><a href="#cb44-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-408"><a href="#cb44-408" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-409"><a href="#cb44-409" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: feature-importance</span></span>
<span id="cb44-410"><a href="#cb44-410" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-411"><a href="#cb44-411" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Feature Importance Rankings from Random Forest Model"</span></span>
<span id="cb44-412"><a href="#cb44-412" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 8</span></span>
<span id="cb44-413"><a href="#cb44-413" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 10</span></span>
<span id="cb44-414"><a href="#cb44-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-415"><a href="#cb44-415" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract feature importances</span></span>
<span id="cb44-416"><a href="#cb44-416" aria-hidden="true" tabindex="-1"></a>feature_importances <span class="op">=</span> rf_classifier.feature_importances_</span>
<span id="cb44-417"><a href="#cb44-417" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> np.argsort(feature_importances)[::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb44-418"><a href="#cb44-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-419"><a href="#cb44-419" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize top 20 most important features</span></span>
<span id="cb44-420"><a href="#cb44-420" aria-hidden="true" tabindex="-1"></a>top_n <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb44-421"><a href="#cb44-421" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb44-422"><a href="#cb44-422" aria-hidden="true" tabindex="-1"></a>plt.barh(<span class="bu">range</span>(top_n), feature_importances[indices[:top_n]])</span>
<span id="cb44-423"><a href="#cb44-423" aria-hidden="true" tabindex="-1"></a>plt.yticks(<span class="bu">range</span>(top_n), [<span class="ss">f'Feature </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> indices[:top_n]])</span>
<span id="cb44-424"><a href="#cb44-424" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Importance Score'</span>)</span>
<span id="cb44-425"><a href="#cb44-425" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Features'</span>)</span>
<span id="cb44-426"><a href="#cb44-426" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Top 20 Feature Importances'</span>)</span>
<span id="cb44-427"><a href="#cb44-427" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_yaxis()</span>
<span id="cb44-428"><a href="#cb44-428" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb44-429"><a href="#cb44-429" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb44-430"><a href="#cb44-430" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-431"><a href="#cb44-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-432"><a href="#cb44-432" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hyperparameter Tuning for Large Datasets</span></span>
<span id="cb44-433"><a href="#cb44-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-436"><a href="#cb44-436" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-437"><a href="#cb44-437" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: hyperparameter-tuning</span></span>
<span id="cb44-438"><a href="#cb44-438" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-439"><a href="#cb44-439" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-440"><a href="#cb44-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-441"><a href="#cb44-441" aria-hidden="true" tabindex="-1"></a><span class="co"># Define parameter grid for optimization</span></span>
<span id="cb44-442"><a href="#cb44-442" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb44-443"><a href="#cb44-443" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: [<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>],</span>
<span id="cb44-444"><a href="#cb44-444" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="dv">10</span>, <span class="dv">20</span>, <span class="va">None</span>],</span>
<span id="cb44-445"><a href="#cb44-445" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_split'</span>: [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>],</span>
<span id="cb44-446"><a href="#cb44-446" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_features'</span>: [<span class="st">'sqrt'</span>, <span class="st">'log2'</span>]</span>
<span id="cb44-447"><a href="#cb44-447" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb44-448"><a href="#cb44-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-449"><a href="#cb44-449" aria-hidden="true" tabindex="-1"></a><span class="co"># Use a subset for faster grid search on large datasets</span></span>
<span id="cb44-450"><a href="#cb44-450" aria-hidden="true" tabindex="-1"></a>X_train_subset <span class="op">=</span> X_train[:<span class="dv">10000</span>]  <span class="co"># Sample for grid search</span></span>
<span id="cb44-451"><a href="#cb44-451" aria-hidden="true" tabindex="-1"></a>y_train_subset <span class="op">=</span> y_train[:<span class="dv">10000</span>]</span>
<span id="cb44-452"><a href="#cb44-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-453"><a href="#cb44-453" aria-hidden="true" tabindex="-1"></a><span class="co"># Grid search with cross-validation</span></span>
<span id="cb44-454"><a href="#cb44-454" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(</span>
<span id="cb44-455"><a href="#cb44-455" aria-hidden="true" tabindex="-1"></a>    RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>),</span>
<span id="cb44-456"><a href="#cb44-456" aria-hidden="true" tabindex="-1"></a>    param_grid,</span>
<span id="cb44-457"><a href="#cb44-457" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">3</span>,                          <span class="co"># 3-fold cross-validation</span></span>
<span id="cb44-458"><a href="#cb44-458" aria-hidden="true" tabindex="-1"></a>    scoring<span class="op">=</span><span class="st">'accuracy'</span>,</span>
<span id="cb44-459"><a href="#cb44-459" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb44-460"><a href="#cb44-460" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">1</span></span>
<span id="cb44-461"><a href="#cb44-461" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-462"><a href="#cb44-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-463"><a href="#cb44-463" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train_subset, y_train_subset)</span>
<span id="cb44-464"><a href="#cb44-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-465"><a href="#cb44-465" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Parameters:"</span>, grid_search.best_params_)</span>
<span id="cb44-466"><a href="#cb44-466" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Cross-Validation Score:"</span>, grid_search.best_score_)</span>
<span id="cb44-467"><a href="#cb44-467" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-468"><a href="#cb44-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-469"><a href="#cb44-469" aria-hidden="true" tabindex="-1"></a><span class="fu">### Random Forest Regressor: Regression Applications</span></span>
<span id="cb44-470"><a href="#cb44-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-473"><a href="#cb44-473" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-474"><a href="#cb44-474" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: rf-regressor</span></span>
<span id="cb44-475"><a href="#cb44-475" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-476"><a href="#cb44-476" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-477"><a href="#cb44-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-478"><a href="#cb44-478" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate regression dataset</span></span>
<span id="cb44-479"><a href="#cb44-479" aria-hidden="true" tabindex="-1"></a>X_reg, y_reg <span class="op">=</span> make_regression(</span>
<span id="cb44-480"><a href="#cb44-480" aria-hidden="true" tabindex="-1"></a>    n_samples<span class="op">=</span><span class="dv">10000</span>,</span>
<span id="cb44-481"><a href="#cb44-481" aria-hidden="true" tabindex="-1"></a>    n_features<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb44-482"><a href="#cb44-482" aria-hidden="true" tabindex="-1"></a>    n_informative<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb44-483"><a href="#cb44-483" aria-hidden="true" tabindex="-1"></a>    noise<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb44-484"><a href="#cb44-484" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb44-485"><a href="#cb44-485" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-486"><a href="#cb44-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-487"><a href="#cb44-487" aria-hidden="true" tabindex="-1"></a>X_train_reg, X_test_reg, y_train_reg, y_test_reg <span class="op">=</span> train_test_split(</span>
<span id="cb44-488"><a href="#cb44-488" aria-hidden="true" tabindex="-1"></a>    X_reg, y_reg, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb44-489"><a href="#cb44-489" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-490"><a href="#cb44-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-491"><a href="#cb44-491" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest Regressor</span></span>
<span id="cb44-492"><a href="#cb44-492" aria-hidden="true" tabindex="-1"></a>rf_regressor <span class="op">=</span> RandomForestRegressor(</span>
<span id="cb44-493"><a href="#cb44-493" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb44-494"><a href="#cb44-494" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb44-495"><a href="#cb44-495" aria-hidden="true" tabindex="-1"></a>    min_samples_split<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb44-496"><a href="#cb44-496" aria-hidden="true" tabindex="-1"></a>    max_features<span class="op">=</span><span class="va">None</span>,  <span class="co"># None uses all features (default for regression)</span></span>
<span id="cb44-497"><a href="#cb44-497" aria-hidden="true" tabindex="-1"></a>    bootstrap<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb44-498"><a href="#cb44-498" aria-hidden="true" tabindex="-1"></a>    oob_score<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb44-499"><a href="#cb44-499" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb44-500"><a href="#cb44-500" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb44-501"><a href="#cb44-501" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-502"><a href="#cb44-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-503"><a href="#cb44-503" aria-hidden="true" tabindex="-1"></a>rf_regressor.fit(X_train_reg, y_train_reg)</span>
<span id="cb44-504"><a href="#cb44-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-505"><a href="#cb44-505" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions and evaluation</span></span>
<span id="cb44-506"><a href="#cb44-506" aria-hidden="true" tabindex="-1"></a>y_pred_reg <span class="op">=</span> rf_regressor.predict(X_test_reg)</span>
<span id="cb44-507"><a href="#cb44-507" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test_reg, y_pred_reg)</span>
<span id="cb44-508"><a href="#cb44-508" aria-hidden="true" tabindex="-1"></a>r2 <span class="op">=</span> r2_score(y_test_reg, y_pred_reg)</span>
<span id="cb44-509"><a href="#cb44-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-510"><a href="#cb44-510" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean Squared Error: </span><span class="sc">{</span>mse<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb44-511"><a href="#cb44-511" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"R² Score: </span><span class="sc">{</span>r2<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb44-512"><a href="#cb44-512" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Out-of-Bag Score: </span><span class="sc">{</span>rf_regressor<span class="sc">.</span>oob_score_<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb44-513"><a href="#cb44-513" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-514"><a href="#cb44-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-515"><a href="#cb44-515" aria-hidden="true" tabindex="-1"></a><span class="fu">### Handling Imbalanced Datasets</span></span>
<span id="cb44-516"><a href="#cb44-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-519"><a href="#cb44-519" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-520"><a href="#cb44-520" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: imbalanced-data</span></span>
<span id="cb44-521"><a href="#cb44-521" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-522"><a href="#cb44-522" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-523"><a href="#cb44-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-524"><a href="#cb44-524" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb44-525"><a href="#cb44-525" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb44-526"><a href="#cb44-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-527"><a href="#cb44-527" aria-hidden="true" tabindex="-1"></a><span class="co"># Create imbalanced dataset</span></span>
<span id="cb44-528"><a href="#cb44-528" aria-hidden="true" tabindex="-1"></a>X_imb, y_imb <span class="op">=</span> make_classification(</span>
<span id="cb44-529"><a href="#cb44-529" aria-hidden="true" tabindex="-1"></a>    n_samples<span class="op">=</span><span class="dv">10000</span>,</span>
<span id="cb44-530"><a href="#cb44-530" aria-hidden="true" tabindex="-1"></a>    n_features<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb44-531"><a href="#cb44-531" aria-hidden="true" tabindex="-1"></a>    n_informative<span class="op">=</span><span class="dv">15</span>,</span>
<span id="cb44-532"><a href="#cb44-532" aria-hidden="true" tabindex="-1"></a>    weights<span class="op">=</span>[<span class="fl">0.9</span>, <span class="fl">0.1</span>],  <span class="co"># 90% class 0, 10% class 1</span></span>
<span id="cb44-533"><a href="#cb44-533" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb44-534"><a href="#cb44-534" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-535"><a href="#cb44-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-536"><a href="#cb44-536" aria-hidden="true" tabindex="-1"></a>X_train_imb, X_test_imb, y_train_imb, y_test_imb <span class="op">=</span> train_test_split(</span>
<span id="cb44-537"><a href="#cb44-537" aria-hidden="true" tabindex="-1"></a>    X_imb, y_imb, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y_imb</span>
<span id="cb44-538"><a href="#cb44-538" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-539"><a href="#cb44-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-540"><a href="#cb44-540" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest with class_weight='balanced'</span></span>
<span id="cb44-541"><a href="#cb44-541" aria-hidden="true" tabindex="-1"></a>rf_balanced <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb44-542"><a href="#cb44-542" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb44-543"><a href="#cb44-543" aria-hidden="true" tabindex="-1"></a>    class_weight<span class="op">=</span><span class="st">'balanced'</span>,  <span class="co"># Automatically adjust class weights</span></span>
<span id="cb44-544"><a href="#cb44-544" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb44-545"><a href="#cb44-545" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb44-546"><a href="#cb44-546" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-547"><a href="#cb44-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-548"><a href="#cb44-548" aria-hidden="true" tabindex="-1"></a>rf_balanced.fit(X_train_imb, y_train_imb)</span>
<span id="cb44-549"><a href="#cb44-549" aria-hidden="true" tabindex="-1"></a>y_pred_imb <span class="op">=</span> rf_balanced.predict(X_test_imb)</span>
<span id="cb44-550"><a href="#cb44-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-551"><a href="#cb44-551" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classification Report (Balanced Random Forest):"</span>)</span>
<span id="cb44-552"><a href="#cb44-552" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test_imb, y_pred_imb))</span>
<span id="cb44-553"><a href="#cb44-553" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-554"><a href="#cb44-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-555"><a href="#cb44-555" aria-hidden="true" tabindex="-1"></a><span class="fu">## Performance Optimization for Large Datasets</span></span>
<span id="cb44-556"><a href="#cb44-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-557"><a href="#cb44-557" aria-hidden="true" tabindex="-1"></a><span class="fu">### Incremental Learning and Memory Efficiency</span></span>
<span id="cb44-558"><a href="#cb44-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-561"><a href="#cb44-561" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-562"><a href="#cb44-562" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: memory-optimization</span></span>
<span id="cb44-563"><a href="#cb44-563" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-564"><a href="#cb44-564" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-565"><a href="#cb44-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-566"><a href="#cb44-566" aria-hidden="true" tabindex="-1"></a><span class="co"># For very large datasets, consider these strategies:</span></span>
<span id="cb44-567"><a href="#cb44-567" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Use max_samples parameter to limit bootstrap sample size</span></span>
<span id="cb44-568"><a href="#cb44-568" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Set max_depth to prevent excessive memory usage</span></span>
<span id="cb44-569"><a href="#cb44-569" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Use warm_start for incremental training</span></span>
<span id="cb44-570"><a href="#cb44-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-571"><a href="#cb44-571" aria-hidden="true" tabindex="-1"></a>rf_efficient <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb44-572"><a href="#cb44-572" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb44-573"><a href="#cb44-573" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">15</span>,              <span class="co"># Limit tree depth</span></span>
<span id="cb44-574"><a href="#cb44-574" aria-hidden="true" tabindex="-1"></a>    max_samples<span class="op">=</span><span class="fl">0.5</span>,           <span class="co"># Use 50% of data for each tree</span></span>
<span id="cb44-575"><a href="#cb44-575" aria-hidden="true" tabindex="-1"></a>    max_features<span class="op">=</span><span class="st">'sqrt'</span>,</span>
<span id="cb44-576"><a href="#cb44-576" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb44-577"><a href="#cb44-577" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb44-578"><a href="#cb44-578" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-579"><a href="#cb44-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-580"><a href="#cb44-580" aria-hidden="true" tabindex="-1"></a><span class="co"># Train on large dataset</span></span>
<span id="cb44-581"><a href="#cb44-581" aria-hidden="true" tabindex="-1"></a>rf_efficient.fit(X_train, y_train)</span>
<span id="cb44-582"><a href="#cb44-582" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Model trained successfully on </span><span class="sc">{</span>X_train<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb44-583"><a href="#cb44-583" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Memory-efficient configuration completed"</span>)</span>
<span id="cb44-584"><a href="#cb44-584" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-585"><a href="#cb44-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-586"><a href="#cb44-586" aria-hidden="true" tabindex="-1"></a><span class="fu">### Parallel Processing Configuration</span></span>
<span id="cb44-587"><a href="#cb44-587" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-590"><a href="#cb44-590" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-591"><a href="#cb44-591" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: parallel-processing</span></span>
<span id="cb44-592"><a href="#cb44-592" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-593"><a href="#cb44-593" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-594"><a href="#cb44-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-595"><a href="#cb44-595" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb44-596"><a href="#cb44-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-597"><a href="#cb44-597" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare sequential vs parallel processing</span></span>
<span id="cb44-598"><a href="#cb44-598" aria-hidden="true" tabindex="-1"></a>X_sample <span class="op">=</span> X_train[:<span class="dv">5000</span>]</span>
<span id="cb44-599"><a href="#cb44-599" aria-hidden="true" tabindex="-1"></a>y_sample <span class="op">=</span> y_train[:<span class="dv">5000</span>]</span>
<span id="cb44-600"><a href="#cb44-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-601"><a href="#cb44-601" aria-hidden="true" tabindex="-1"></a><span class="co"># Sequential processing</span></span>
<span id="cb44-602"><a href="#cb44-602" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb44-603"><a href="#cb44-603" aria-hidden="true" tabindex="-1"></a>rf_seq <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, n_jobs<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb44-604"><a href="#cb44-604" aria-hidden="true" tabindex="-1"></a>rf_seq.fit(X_sample, y_sample)</span>
<span id="cb44-605"><a href="#cb44-605" aria-hidden="true" tabindex="-1"></a>seq_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb44-606"><a href="#cb44-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-607"><a href="#cb44-607" aria-hidden="true" tabindex="-1"></a><span class="co"># Parallel processing</span></span>
<span id="cb44-608"><a href="#cb44-608" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb44-609"><a href="#cb44-609" aria-hidden="true" tabindex="-1"></a>rf_par <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb44-610"><a href="#cb44-610" aria-hidden="true" tabindex="-1"></a>rf_par.fit(X_sample, y_sample)</span>
<span id="cb44-611"><a href="#cb44-611" aria-hidden="true" tabindex="-1"></a>par_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb44-612"><a href="#cb44-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-613"><a href="#cb44-613" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sequential time: </span><span class="sc">{</span>seq_time<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb44-614"><a href="#cb44-614" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Parallel time: </span><span class="sc">{</span>par_time<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb44-615"><a href="#cb44-615" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Speedup: </span><span class="sc">{</span>seq_time<span class="op">/</span>par_time<span class="sc">:.2f}</span><span class="ss">x"</span>)</span>
<span id="cb44-616"><a href="#cb44-616" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-617"><a href="#cb44-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-618"><a href="#cb44-618" aria-hidden="true" tabindex="-1"></a><span class="fu">## Datasets for Random Forest Applications</span></span>
<span id="cb44-619"><a href="#cb44-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-620"><a href="#cb44-620" aria-hidden="true" tabindex="-1"></a><span class="fu">### Publicly Available Large-Scale Datasets</span></span>
<span id="cb44-621"><a href="#cb44-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-622"><a href="#cb44-622" aria-hidden="true" tabindex="-1"></a>The following datasets are excellent for demonstrating Random Forest algorithms on large-scale problems:</span>
<span id="cb44-623"><a href="#cb44-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-624"><a href="#cb44-624" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Classification Datasets</span></span>
<span id="cb44-625"><a href="#cb44-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-626"><a href="#cb44-626" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**UCI Machine Learning Repository**</span>
<span id="cb44-627"><a href="#cb44-627" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>URL: https://archive.ics.uci.edu/</span>
<span id="cb44-628"><a href="#cb44-628" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Notable datasets: Covertype, KDD Cup 1999, Adult Census</span>
<span id="cb44-629"><a href="#cb44-629" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Access: Direct download via Python <span class="in">`sklearn.datasets`</span> or manual download</span>
<span id="cb44-630"><a href="#cb44-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-631"><a href="#cb44-631" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Kaggle Datasets**</span>
<span id="cb44-632"><a href="#cb44-632" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>URL: https://www.kaggle.com/datasets</span>
<span id="cb44-633"><a href="#cb44-633" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Large-scale competitions: Titanic, House Prices, Credit Card Fraud Detection</span>
<span id="cb44-634"><a href="#cb44-634" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Access: Requires Kaggle account and API key</span>
<span id="cb44-635"><a href="#cb44-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-636"><a href="#cb44-636" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**OpenML**</span>
<span id="cb44-637"><a href="#cb44-637" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>URL: https://www.openml.org/</span>
<span id="cb44-638"><a href="#cb44-638" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Access via Python: <span class="in">`from openml import datasets`</span></span>
<span id="cb44-639"><a href="#cb44-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-642"><a href="#cb44-642" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-643"><a href="#cb44-643" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: dataset-access</span></span>
<span id="cb44-644"><a href="#cb44-644" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-645"><a href="#cb44-645" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-646"><a href="#cb44-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-647"><a href="#cb44-647" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Loading UCI datasets via scikit-learn</span></span>
<span id="cb44-648"><a href="#cb44-648" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb44-649"><a href="#cb44-649" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_covtype</span>
<span id="cb44-650"><a href="#cb44-650" aria-hidden="true" tabindex="-1"></a>    covtype <span class="op">=</span> fetch_covtype()</span>
<span id="cb44-651"><a href="#cb44-651" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Covertype dataset shape: </span><span class="sc">{</span>covtype<span class="sc">.</span>data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-652"><a href="#cb44-652" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Number of classes: </span><span class="sc">{</span><span class="bu">len</span>(np.unique(covtype.target))<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-653"><a href="#cb44-653" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span>:</span>
<span id="cb44-654"><a href="#cb44-654" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Dataset fetch requires internet connection"</span>)</span>
<span id="cb44-655"><a href="#cb44-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-656"><a href="#cb44-656" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Using OpenML</span></span>
<span id="cb44-657"><a href="#cb44-657" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb44-658"><a href="#cb44-658" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> openml.datasets <span class="im">import</span> get_dataset</span>
<span id="cb44-659"><a href="#cb44-659" aria-hidden="true" tabindex="-1"></a>    <span class="co"># dataset = get_dataset(1)  # Uncomment to fetch specific dataset</span></span>
<span id="cb44-660"><a href="#cb44-660" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"OpenML integration available"</span>)</span>
<span id="cb44-661"><a href="#cb44-661" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb44-662"><a href="#cb44-662" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Install openml: pip install openml"</span>)</span>
<span id="cb44-663"><a href="#cb44-663" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-664"><a href="#cb44-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-665"><a href="#cb44-665" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Regression Datasets</span></span>
<span id="cb44-666"><a href="#cb44-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-667"><a href="#cb44-667" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**California Housing Dataset** (Built-in scikit-learn)</span>
<span id="cb44-668"><a href="#cb44-668" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Boston Housing Dataset** (Historical, now deprecated)</span>
<span id="cb44-669"><a href="#cb44-669" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Ames Housing Dataset** (Kaggle)</span>
<span id="cb44-670"><a href="#cb44-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-673"><a href="#cb44-673" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-674"><a href="#cb44-674" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: regression-datasets</span></span>
<span id="cb44-675"><a href="#cb44-675" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-676"><a href="#cb44-676" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-677"><a href="#cb44-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-678"><a href="#cb44-678" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_california_housing</span>
<span id="cb44-679"><a href="#cb44-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-680"><a href="#cb44-680" aria-hidden="true" tabindex="-1"></a>housing <span class="op">=</span> fetch_california_housing()</span>
<span id="cb44-681"><a href="#cb44-681" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"California Housing dataset shape: </span><span class="sc">{</span>housing<span class="sc">.</span>data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-682"><a href="#cb44-682" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Features: </span><span class="sc">{</span>housing<span class="sc">.</span>feature_names<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-683"><a href="#cb44-683" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-684"><a href="#cb44-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-685"><a href="#cb44-685" aria-hidden="true" tabindex="-1"></a><span class="fu">### Dataset Loading Function</span></span>
<span id="cb44-686"><a href="#cb44-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-689"><a href="#cb44-689" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-690"><a href="#cb44-690" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: dataset-loader</span></span>
<span id="cb44-691"><a href="#cb44-691" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-692"><a href="#cb44-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-693"><a href="#cb44-693" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_dataset(dataset_name<span class="op">=</span><span class="st">'synthetic'</span>, n_samples<span class="op">=</span><span class="dv">10000</span>):</span>
<span id="cb44-694"><a href="#cb44-694" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb44-695"><a href="#cb44-695" aria-hidden="true" tabindex="-1"></a><span class="co">    Unified dataset loading function.</span></span>
<span id="cb44-696"><a href="#cb44-696" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb44-697"><a href="#cb44-697" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb44-698"><a href="#cb44-698" aria-hidden="true" tabindex="-1"></a><span class="co">    -----------</span></span>
<span id="cb44-699"><a href="#cb44-699" aria-hidden="true" tabindex="-1"></a><span class="co">    dataset_name : str</span></span>
<span id="cb44-700"><a href="#cb44-700" aria-hidden="true" tabindex="-1"></a><span class="co">        Name of dataset ('synthetic', 'california_housing', etc.)</span></span>
<span id="cb44-701"><a href="#cb44-701" aria-hidden="true" tabindex="-1"></a><span class="co">    n_samples : int</span></span>
<span id="cb44-702"><a href="#cb44-702" aria-hidden="true" tabindex="-1"></a><span class="co">        For synthetic datasets</span></span>
<span id="cb44-703"><a href="#cb44-703" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb44-704"><a href="#cb44-704" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb44-705"><a href="#cb44-705" aria-hidden="true" tabindex="-1"></a><span class="co">    --------</span></span>
<span id="cb44-706"><a href="#cb44-706" aria-hidden="true" tabindex="-1"></a><span class="co">    X, y : tuple</span></span>
<span id="cb44-707"><a href="#cb44-707" aria-hidden="true" tabindex="-1"></a><span class="co">        Feature matrix and target</span></span>
<span id="cb44-708"><a href="#cb44-708" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb44-709"><a href="#cb44-709" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> dataset_name <span class="op">==</span> <span class="st">'synthetic'</span>:</span>
<span id="cb44-710"><a href="#cb44-710" aria-hidden="true" tabindex="-1"></a>        X, y <span class="op">=</span> make_classification(</span>
<span id="cb44-711"><a href="#cb44-711" aria-hidden="true" tabindex="-1"></a>            n_samples<span class="op">=</span>n_samples,</span>
<span id="cb44-712"><a href="#cb44-712" aria-hidden="true" tabindex="-1"></a>            n_features<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb44-713"><a href="#cb44-713" aria-hidden="true" tabindex="-1"></a>            n_informative<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb44-714"><a href="#cb44-714" aria-hidden="true" tabindex="-1"></a>            random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb44-715"><a href="#cb44-715" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb44-716"><a href="#cb44-716" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> dataset_name <span class="op">==</span> <span class="st">'california_housing'</span>:</span>
<span id="cb44-717"><a href="#cb44-717" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> fetch_california_housing()</span>
<span id="cb44-718"><a href="#cb44-718" aria-hidden="true" tabindex="-1"></a>        X, y <span class="op">=</span> data.data, data.target</span>
<span id="cb44-719"><a href="#cb44-719" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb44-720"><a href="#cb44-720" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Unknown dataset: </span><span class="sc">{</span>dataset_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-721"><a href="#cb44-721" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-722"><a href="#cb44-722" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X, y</span>
<span id="cb44-723"><a href="#cb44-723" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-724"><a href="#cb44-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-725"><a href="#cb44-725" aria-hidden="true" tabindex="-1"></a><span class="fu">## Further Machine Learning Resources</span></span>
<span id="cb44-726"><a href="#cb44-726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-727"><a href="#cb44-727" aria-hidden="true" tabindex="-1"></a><span class="fu">### Online Courses and Tutorials</span></span>
<span id="cb44-728"><a href="#cb44-728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-729"><a href="#cb44-729" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Coursera - Machine Learning Specialization**</span>
<span id="cb44-730"><a href="#cb44-730" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>URL: https://www.coursera.org/learn/machine-learning</span>
<span id="cb44-731"><a href="#cb44-731" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Covers ensemble methods including Random Forests</span>
<span id="cb44-732"><a href="#cb44-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-733"><a href="#cb44-733" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**edX - MIT Introduction to Machine Learning**</span>
<span id="cb44-734"><a href="#cb44-734" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>URL: https://www.edx.org/course/introduction-to-machine-learning</span>
<span id="cb44-735"><a href="#cb44-735" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Comprehensive coverage of ML fundamentals</span>
<span id="cb44-736"><a href="#cb44-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-737"><a href="#cb44-737" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Fast.ai - Practical Deep Learning**</span>
<span id="cb44-738"><a href="#cb44-738" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>URL: https://www.fast.ai/</span>
<span id="cb44-739"><a href="#cb44-739" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Modern approach to ML with practical applications</span>
<span id="cb44-740"><a href="#cb44-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-741"><a href="#cb44-741" aria-hidden="true" tabindex="-1"></a><span class="fu">### Books and Textbooks</span></span>
<span id="cb44-742"><a href="#cb44-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-743"><a href="#cb44-743" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**"The Elements of Statistical Learning"** by Hastie, Tibshirani, and Friedman</span>
<span id="cb44-744"><a href="#cb44-744" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Comprehensive treatment of statistical learning methods</span>
<span id="cb44-745"><a href="#cb44-745" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Chapter 15 covers Random Forests in detail</span>
<span id="cb44-746"><a href="#cb44-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-747"><a href="#cb44-747" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**"An Introduction to Statistical Learning"** by James et al.</span>
<span id="cb44-748"><a href="#cb44-748" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>More accessible introduction to ML concepts</span>
<span id="cb44-749"><a href="#cb44-749" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Excellent for beginners</span>
<span id="cb44-750"><a href="#cb44-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-751"><a href="#cb44-751" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**"Hands-On Machine Learning"** by Aurélien Géron</span>
<span id="cb44-752"><a href="#cb44-752" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Practical implementation focus</span>
<span id="cb44-753"><a href="#cb44-753" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Code examples in Python</span>
<span id="cb44-754"><a href="#cb44-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-755"><a href="#cb44-755" aria-hidden="true" tabindex="-1"></a><span class="fu">### Software and Libraries</span></span>
<span id="cb44-756"><a href="#cb44-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-757"><a href="#cb44-757" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**scikit-learn** (Python)</span>
<span id="cb44-758"><a href="#cb44-758" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Primary library used in this document</span>
<span id="cb44-759"><a href="#cb44-759" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Documentation: https://scikit-learn.org/stable/</span>
<span id="cb44-760"><a href="#cb44-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-761"><a href="#cb44-761" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**XGBoost** (Gradient Boosting)</span>
<span id="cb44-762"><a href="#cb44-762" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Advanced ensemble method</span>
<span id="cb44-763"><a href="#cb44-763" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>URL: https://xgboost.readthedocs.io/</span>
<span id="cb44-764"><a href="#cb44-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-765"><a href="#cb44-765" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**LightGBM** (Microsoft)</span>
<span id="cb44-766"><a href="#cb44-766" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Fast gradient boosting framework</span>
<span id="cb44-767"><a href="#cb44-767" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>URL: https://lightgbm.readthedocs.io/</span>
<span id="cb44-768"><a href="#cb44-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-769"><a href="#cb44-769" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**R - randomForest package**</span>
<span id="cb44-770"><a href="#cb44-770" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Original implementation by Breiman</span>
<span id="cb44-771"><a href="#cb44-771" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Comprehensive R documentation</span>
<span id="cb44-772"><a href="#cb44-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-773"><a href="#cb44-773" aria-hidden="true" tabindex="-1"></a><span class="fu">### Research Communities</span></span>
<span id="cb44-774"><a href="#cb44-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-775"><a href="#cb44-775" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Papers with Code**</span>
<span id="cb44-776"><a href="#cb44-776" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>URL: https://paperswithcode.com/</span>
<span id="cb44-777"><a href="#cb44-777" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Latest research papers with implementations</span>
<span id="cb44-778"><a href="#cb44-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-779"><a href="#cb44-779" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**arXiv Machine Learning**</span>
<span id="cb44-780"><a href="#cb44-780" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>URL: https://arxiv.org/list/cs.LG/recent</span>
<span id="cb44-781"><a href="#cb44-781" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Preprint repository for ML research</span>
<span id="cb44-782"><a href="#cb44-782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-783"><a href="#cb44-783" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Google Scholar**</span>
<span id="cb44-784"><a href="#cb44-784" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Search for "Random Forest" and related terms</span>
<span id="cb44-785"><a href="#cb44-785" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Track citations and related work</span>
<span id="cb44-786"><a href="#cb44-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-787"><a href="#cb44-787" aria-hidden="true" tabindex="-1"></a><span class="fu">## Literature Review</span></span>
<span id="cb44-788"><a href="#cb44-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-789"><a href="#cb44-789" aria-hidden="true" tabindex="-1"></a><span class="fu">### Foundational Papers</span></span>
<span id="cb44-790"><a href="#cb44-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-791"><a href="#cb44-791" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Breiman, L. (2001). "Random Forests." *Machine Learning*, 45(1), 5-32.**</span>
<span id="cb44-792"><a href="#cb44-792" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Original paper introducing Random Forest algorithm</span>
<span id="cb44-793"><a href="#cb44-793" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Theoretical foundations and empirical evaluations</span>
<span id="cb44-794"><a href="#cb44-794" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>DOI: 10.1023/A:1010933404324</span>
<span id="cb44-795"><a href="#cb44-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-796"><a href="#cb44-796" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Ho, T. K. (1995). "Random Decision Forests." *Proceedings of the 3rd International Conference on Document Analysis and Recognition*, 278-282.**</span>
<span id="cb44-797"><a href="#cb44-797" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Early work on random decision forests</span>
<span id="cb44-798"><a href="#cb44-798" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Precursor to Breiman's Random Forest</span>
<span id="cb44-799"><a href="#cb44-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-800"><a href="#cb44-800" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Breiman, L. (1996). "Bagging Predictors." *Machine Learning*, 24(2), 123-140.**</span>
<span id="cb44-801"><a href="#cb44-801" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Introduction to bootstrap aggregation</span>
<span id="cb44-802"><a href="#cb44-802" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Foundation for ensemble methods</span>
<span id="cb44-803"><a href="#cb44-803" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>DOI: 10.1023/A:1018054314350</span>
<span id="cb44-804"><a href="#cb44-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-805"><a href="#cb44-805" aria-hidden="true" tabindex="-1"></a><span class="fu">### Recent Advances and Applications</span></span>
<span id="cb44-806"><a href="#cb44-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-807"><a href="#cb44-807" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Biau, G., &amp; Scornet, E. (2016). "A Random Forest Guided Tour." *Test*, 25(2), 197-227.**</span>
<span id="cb44-808"><a href="#cb44-808" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Comprehensive review of Random Forest theory</span>
<span id="cb44-809"><a href="#cb44-809" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Statistical properties and consistency results</span>
<span id="cb44-810"><a href="#cb44-810" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>DOI: 10.1007/s11749-016-0481-7</span>
<span id="cb44-811"><a href="#cb44-811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-812"><a href="#cb44-812" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Wright, M. N., &amp; Ziegler, A. (2017). "ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R." *Journal of Statistical Software*, 77(1), 1-17.**</span>
<span id="cb44-813"><a href="#cb44-813" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Efficient implementation for high-dimensional data</span>
<span id="cb44-814"><a href="#cb44-814" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Performance optimizations</span>
<span id="cb44-815"><a href="#cb44-815" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>DOI: 10.18637/jss.v077.i01</span>
<span id="cb44-816"><a href="#cb44-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-817"><a href="#cb44-817" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**Probst, P., Boulesteix, A. L., &amp; Bischl, B. (2019). "Tunability: Importance of Hyperparameters of Machine Learning Algorithms." *Journal of Machine Learning Research*, 20(53), 1-32.**</span>
<span id="cb44-818"><a href="#cb44-818" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Analysis of hyperparameter importance</span>
<span id="cb44-819"><a href="#cb44-819" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Includes Random Forest hyperparameter sensitivity</span>
<span id="cb44-820"><a href="#cb44-820" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>URL: http://jmlr.org/papers/v20/18-444.html</span>
<span id="cb44-821"><a href="#cb44-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-822"><a href="#cb44-822" aria-hidden="true" tabindex="-1"></a><span class="fu">### Large-Scale Applications</span></span>
<span id="cb44-823"><a href="#cb44-823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-824"><a href="#cb44-824" aria-hidden="true" tabindex="-1"></a><span class="ss">7. </span>**Caruana, R., &amp; Niculescu-Mizil, A. (2006). "An Empirical Comparison of Supervised Learning Algorithms." *Proceedings of the 23rd International Conference on Machine Learning*, 161-168.**</span>
<span id="cb44-825"><a href="#cb44-825" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Comparative study including Random Forests</span>
<span id="cb44-826"><a href="#cb44-826" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Performance across multiple datasets</span>
<span id="cb44-827"><a href="#cb44-827" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-828"><a href="#cb44-828" aria-hidden="true" tabindex="-1"></a><span class="ss">8. </span>**Fernández-Delgado, M., et al. (2014). "Do We Need Hundreds of Classifiers to Solve Real World Classification Problems?" *Journal of Machine Learning Research*, 15, 3133-3181.**</span>
<span id="cb44-829"><a href="#cb44-829" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Large-scale comparison of classifiers</span>
<span id="cb44-830"><a href="#cb44-830" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Random Forest performance analysis</span>
<span id="cb44-831"><a href="#cb44-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-832"><a href="#cb44-832" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feature Importance and Interpretability</span></span>
<span id="cb44-833"><a href="#cb44-833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-834"><a href="#cb44-834" aria-hidden="true" tabindex="-1"></a><span class="ss">9. </span>**Strobl, C., et al. (2007). "Bias in Random Forest Variable Importance Measures: Illustrations, Sources and a Solution." *BMC Bioinformatics*, 8(1), 25.**</span>
<span id="cb44-835"><a href="#cb44-835" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Critical analysis of variable importance measures</span>
<span id="cb44-836"><a href="#cb44-836" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Solutions for categorical variables</span>
<span id="cb44-837"><a href="#cb44-837" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>DOI: 10.1186/1471-2105-8-25</span>
<span id="cb44-838"><a href="#cb44-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-839"><a href="#cb44-839" aria-hidden="true" tabindex="-1"></a><span class="ss">10. </span>**Lundberg, S. M., &amp; Lee, S. I. (2017). "A Unified Approach to Interpreting Model Predictions." *Advances in Neural Information Processing Systems*, 30.**</span>
<span id="cb44-840"><a href="#cb44-840" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>SHAP values for model interpretation</span>
<span id="cb44-841"><a href="#cb44-841" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Applicable to Random Forest models</span>
<span id="cb44-842"><a href="#cb44-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-843"><a href="#cb44-843" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theoretical Developments</span></span>
<span id="cb44-844"><a href="#cb44-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-845"><a href="#cb44-845" aria-hidden="true" tabindex="-1"></a><span class="ss">11. </span>**Scornet, E., Biau, G., &amp; Vert, J. P. (2015). "Consistency of Random Forests." *The Annals of Statistics*, 43(4), 1716-1741.**</span>
<span id="cb44-846"><a href="#cb44-846" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Theoretical consistency results</span>
<span id="cb44-847"><a href="#cb44-847" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Asymptotic properties</span>
<span id="cb44-848"><a href="#cb44-848" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>DOI: 10.1214/15-AOS1321</span>
<span id="cb44-849"><a href="#cb44-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-850"><a href="#cb44-850" aria-hidden="true" tabindex="-1"></a><span class="ss">12. </span>**Mentch, L., &amp; Hooker, G. (2016). "Quantifying Uncertainty in Random Forests via Confidence Intervals and Hypothesis Tests." *Journal of Machine Learning Research*, 17(26), 1-41.**</span>
<span id="cb44-851"><a href="#cb44-851" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Statistical inference for Random Forests</span>
<span id="cb44-852"><a href="#cb44-852" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>Confidence intervals and hypothesis testing</span>
<span id="cb44-853"><a href="#cb44-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-854"><a href="#cb44-854" aria-hidden="true" tabindex="-1"></a><span class="fu">## Gradient Boosting Methods</span></span>
<span id="cb44-855"><a href="#cb44-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-856"><a href="#cb44-856" aria-hidden="true" tabindex="-1"></a>Gradient Boosting represents another powerful ensemble learning paradigm that sequentially builds models to correct errors from previous iterations. Unlike Random Forests, which use parallel tree construction, gradient boosting employs sequential, additive modeling to minimize prediction errors.</span>
<span id="cb44-857"><a href="#cb44-857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-858"><a href="#cb44-858" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theoretical Foundations</span></span>
<span id="cb44-859"><a href="#cb44-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-860"><a href="#cb44-860" aria-hidden="true" tabindex="-1"></a>Gradient Boosting iteratively fits weak learners (typically decision trees) to the negative gradient of a loss function. The algorithm minimizes:</span>
<span id="cb44-861"><a href="#cb44-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-862"><a href="#cb44-862" aria-hidden="true" tabindex="-1"></a>$$L(y, F(x)) = \sum_{i=1}^{n} L(y_i, F(x_i))$$</span>
<span id="cb44-863"><a href="#cb44-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-864"><a href="#cb44-864" aria-hidden="true" tabindex="-1"></a>where $F(x) = \sum_{m=1}^{M} \gamma_m h_m(x)$ represents the additive model, and $h_m(x)$ are the base learners.</span>
<span id="cb44-865"><a href="#cb44-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-866"><a href="#cb44-866" aria-hidden="true" tabindex="-1"></a><span class="fu">### XGBoost: Extreme Gradient Boosting</span></span>
<span id="cb44-867"><a href="#cb44-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-868"><a href="#cb44-868" aria-hidden="true" tabindex="-1"></a>XGBoost extends gradient boosting with regularization, parallel processing, and efficient tree construction algorithms.</span>
<span id="cb44-869"><a href="#cb44-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-872"><a href="#cb44-872" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-873"><a href="#cb44-873" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: xgboost-implementation</span></span>
<span id="cb44-874"><a href="#cb44-874" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-875"><a href="#cb44-875" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-876"><a href="#cb44-876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-877"><a href="#cb44-877" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data (outside try block so variables are always available)</span></span>
<span id="cb44-878"><a href="#cb44-878" aria-hidden="true" tabindex="-1"></a>X_train_gb, X_test_gb, y_train_gb, y_test_gb <span class="op">=</span> train_test_split(</span>
<span id="cb44-879"><a href="#cb44-879" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y</span>
<span id="cb44-880"><a href="#cb44-880" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-881"><a href="#cb44-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-882"><a href="#cb44-882" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb44-883"><a href="#cb44-883" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb44-884"><a href="#cb44-884" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, mean_squared_error</span>
<span id="cb44-885"><a href="#cb44-885" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-886"><a href="#cb44-886" aria-hidden="true" tabindex="-1"></a>    <span class="co"># XGBoost Classifier</span></span>
<span id="cb44-887"><a href="#cb44-887" aria-hidden="true" tabindex="-1"></a>    xgb_classifier <span class="op">=</span> xgb.XGBClassifier(</span>
<span id="cb44-888"><a href="#cb44-888" aria-hidden="true" tabindex="-1"></a>        n_estimators<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb44-889"><a href="#cb44-889" aria-hidden="true" tabindex="-1"></a>        max_depth<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb44-890"><a href="#cb44-890" aria-hidden="true" tabindex="-1"></a>        learning_rate<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb44-891"><a href="#cb44-891" aria-hidden="true" tabindex="-1"></a>        subsample<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb44-892"><a href="#cb44-892" aria-hidden="true" tabindex="-1"></a>        colsample_bytree<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb44-893"><a href="#cb44-893" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb44-894"><a href="#cb44-894" aria-hidden="true" tabindex="-1"></a>        n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb44-895"><a href="#cb44-895" aria-hidden="true" tabindex="-1"></a>        tree_method<span class="op">=</span><span class="st">'hist'</span>  <span class="co"># Efficient histogram-based algorithm</span></span>
<span id="cb44-896"><a href="#cb44-896" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb44-897"><a href="#cb44-897" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-898"><a href="#cb44-898" aria-hidden="true" tabindex="-1"></a>    xgb_classifier.fit(X_train_gb, y_train_gb)</span>
<span id="cb44-899"><a href="#cb44-899" aria-hidden="true" tabindex="-1"></a>    y_pred_xgb <span class="op">=</span> xgb_classifier.predict(X_test_gb)</span>
<span id="cb44-900"><a href="#cb44-900" aria-hidden="true" tabindex="-1"></a>    xgb_accuracy <span class="op">=</span> accuracy_score(y_test_gb, y_pred_xgb)</span>
<span id="cb44-901"><a href="#cb44-901" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-902"><a href="#cb44-902" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"XGBoost Accuracy: </span><span class="sc">{</span>xgb_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb44-903"><a href="#cb44-903" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Feature Importance (Top 5):"</span>)</span>
<span id="cb44-904"><a href="#cb44-904" aria-hidden="true" tabindex="-1"></a>    feature_imp <span class="op">=</span> xgb_classifier.feature_importances_</span>
<span id="cb44-905"><a href="#cb44-905" aria-hidden="true" tabindex="-1"></a>    top_indices <span class="op">=</span> np.argsort(feature_imp)[::<span class="op">-</span><span class="dv">1</span>][:<span class="dv">5</span>]</span>
<span id="cb44-906"><a href="#cb44-906" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> top_indices:</span>
<span id="cb44-907"><a href="#cb44-907" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Feature </span><span class="sc">{</span>idx<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>feature_imp[idx]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb44-908"><a href="#cb44-908" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb44-909"><a href="#cb44-909" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb44-910"><a href="#cb44-910" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"XGBoost not installed. Install with: pip install xgboost"</span>)</span>
<span id="cb44-911"><a href="#cb44-911" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-912"><a href="#cb44-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-913"><a href="#cb44-913" aria-hidden="true" tabindex="-1"></a><span class="fu">### LightGBM: Light Gradient Boosting Machine</span></span>
<span id="cb44-914"><a href="#cb44-914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-915"><a href="#cb44-915" aria-hidden="true" tabindex="-1"></a>LightGBM uses gradient-based one-side sampling (GOSS) and exclusive feature bundling (EFB) for improved efficiency on large datasets.</span>
<span id="cb44-916"><a href="#cb44-916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-919"><a href="#cb44-919" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-920"><a href="#cb44-920" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: lightgbm-implementation</span></span>
<span id="cb44-921"><a href="#cb44-921" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-922"><a href="#cb44-922" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-923"><a href="#cb44-923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-924"><a href="#cb44-924" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb44-925"><a href="#cb44-925" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> lightgbm <span class="im">as</span> lgb</span>
<span id="cb44-926"><a href="#cb44-926" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-927"><a href="#cb44-927" aria-hidden="true" tabindex="-1"></a>    <span class="co"># LightGBM Classifier</span></span>
<span id="cb44-928"><a href="#cb44-928" aria-hidden="true" tabindex="-1"></a>    lgb_classifier <span class="op">=</span> lgb.LGBMClassifier(</span>
<span id="cb44-929"><a href="#cb44-929" aria-hidden="true" tabindex="-1"></a>        n_estimators<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb44-930"><a href="#cb44-930" aria-hidden="true" tabindex="-1"></a>        max_depth<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb44-931"><a href="#cb44-931" aria-hidden="true" tabindex="-1"></a>        learning_rate<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb44-932"><a href="#cb44-932" aria-hidden="true" tabindex="-1"></a>        subsample<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb44-933"><a href="#cb44-933" aria-hidden="true" tabindex="-1"></a>        colsample_bytree<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb44-934"><a href="#cb44-934" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb44-935"><a href="#cb44-935" aria-hidden="true" tabindex="-1"></a>        n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb44-936"><a href="#cb44-936" aria-hidden="true" tabindex="-1"></a>        verbose<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb44-937"><a href="#cb44-937" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb44-938"><a href="#cb44-938" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-939"><a href="#cb44-939" aria-hidden="true" tabindex="-1"></a>    lgb_classifier.fit(X_train_gb, y_train_gb)</span>
<span id="cb44-940"><a href="#cb44-940" aria-hidden="true" tabindex="-1"></a>    y_pred_lgb <span class="op">=</span> lgb_classifier.predict(X_test_gb)</span>
<span id="cb44-941"><a href="#cb44-941" aria-hidden="true" tabindex="-1"></a>    lgb_accuracy <span class="op">=</span> accuracy_score(y_test_gb, y_pred_lgb)</span>
<span id="cb44-942"><a href="#cb44-942" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-943"><a href="#cb44-943" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"LightGBM Accuracy: </span><span class="sc">{</span>lgb_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb44-944"><a href="#cb44-944" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Training time advantage: LightGBM is typically faster than XGBoost"</span>)</span>
<span id="cb44-945"><a href="#cb44-945" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-946"><a href="#cb44-946" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb44-947"><a href="#cb44-947" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"LightGBM not installed. Install with: pip install lightgbm"</span>)</span>
<span id="cb44-948"><a href="#cb44-948" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-949"><a href="#cb44-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-950"><a href="#cb44-950" aria-hidden="true" tabindex="-1"></a><span class="fu">### Comparison: Random Forest vs Gradient Boosting</span></span>
<span id="cb44-951"><a href="#cb44-951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-954"><a href="#cb44-954" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-955"><a href="#cb44-955" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: ensemble-comparison</span></span>
<span id="cb44-956"><a href="#cb44-956" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-957"><a href="#cb44-957" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-958"><a href="#cb44-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-959"><a href="#cb44-959" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb44-960"><a href="#cb44-960" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb44-961"><a href="#cb44-961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-962"><a href="#cb44-962" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare smaller subset for fair comparison</span></span>
<span id="cb44-963"><a href="#cb44-963" aria-hidden="true" tabindex="-1"></a>X_comp <span class="op">=</span> X_train_gb[:<span class="dv">10000</span>]</span>
<span id="cb44-964"><a href="#cb44-964" aria-hidden="true" tabindex="-1"></a>y_comp <span class="op">=</span> y_train_gb[:<span class="dv">10000</span>]</span>
<span id="cb44-965"><a href="#cb44-965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-966"><a href="#cb44-966" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest</span></span>
<span id="cb44-967"><a href="#cb44-967" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb44-968"><a href="#cb44-968" aria-hidden="true" tabindex="-1"></a>rf_comp <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb44-969"><a href="#cb44-969" aria-hidden="true" tabindex="-1"></a>rf_comp.fit(X_comp, y_comp)</span>
<span id="cb44-970"><a href="#cb44-970" aria-hidden="true" tabindex="-1"></a>rf_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb44-971"><a href="#cb44-971" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-972"><a href="#cb44-972" aria-hidden="true" tabindex="-1"></a><span class="co"># XGBoost</span></span>
<span id="cb44-973"><a href="#cb44-973" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb44-974"><a href="#cb44-974" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb44-975"><a href="#cb44-975" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> time.time()</span>
<span id="cb44-976"><a href="#cb44-976" aria-hidden="true" tabindex="-1"></a>    xgb_comp <span class="op">=</span> xgb.XGBClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>, tree_method<span class="op">=</span><span class="st">'hist'</span>)</span>
<span id="cb44-977"><a href="#cb44-977" aria-hidden="true" tabindex="-1"></a>    xgb_comp.fit(X_comp, y_comp)</span>
<span id="cb44-978"><a href="#cb44-978" aria-hidden="true" tabindex="-1"></a>    xgb_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb44-979"><a href="#cb44-979" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-980"><a href="#cb44-980" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Training Time Comparison (10,000 samples):"</span>)</span>
<span id="cb44-981"><a href="#cb44-981" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Random Forest: </span><span class="sc">{</span>rf_time<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb44-982"><a href="#cb44-982" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  XGBoost: </span><span class="sc">{</span>xgb_time<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb44-983"><a href="#cb44-983" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Speedup: </span><span class="sc">{</span>rf_time<span class="op">/</span>xgb_time<span class="sc">:.2f}</span><span class="ss">x"</span>)</span>
<span id="cb44-984"><a href="#cb44-984" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb44-985"><a href="#cb44-985" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"XGBoost comparison requires xgboost installation"</span>)</span>
<span id="cb44-986"><a href="#cb44-986" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb44-987"><a href="#cb44-987" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"XGBoost comparison error: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-988"><a href="#cb44-988" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-989"><a href="#cb44-989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-990"><a href="#cb44-990" aria-hidden="true" tabindex="-1"></a><span class="fu">## Support Vector Machines for Large-Scale Data</span></span>
<span id="cb44-991"><a href="#cb44-991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-992"><a href="#cb44-992" aria-hidden="true" tabindex="-1"></a>Support Vector Machines (SVMs) are powerful for classification and regression, but traditional implementations scale poorly with large datasets. Modern approaches use kernel approximations and linear SVMs for scalability.</span>
<span id="cb44-993"><a href="#cb44-993" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-994"><a href="#cb44-994" aria-hidden="true" tabindex="-1"></a><span class="fu">### Linear SVM with Stochastic Gradient Descent</span></span>
<span id="cb44-995"><a href="#cb44-995" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-998"><a href="#cb44-998" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-999"><a href="#cb44-999" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: linear-svm</span></span>
<span id="cb44-1000"><a href="#cb44-1000" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-1001"><a href="#cb44-1001" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-1002"><a href="#cb44-1002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1003"><a href="#cb44-1003" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> SGDClassifier</span>
<span id="cb44-1004"><a href="#cb44-1004" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb44-1005"><a href="#cb44-1005" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1006"><a href="#cb44-1006" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear SVM using SGD (scales to millions of samples)</span></span>
<span id="cb44-1007"><a href="#cb44-1007" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb44-1008"><a href="#cb44-1008" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler.fit_transform(X_train_gb)</span>
<span id="cb44-1009"><a href="#cb44-1009" aria-hidden="true" tabindex="-1"></a>X_test_scaled <span class="op">=</span> scaler.transform(X_test_gb)</span>
<span id="cb44-1010"><a href="#cb44-1010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1011"><a href="#cb44-1011" aria-hidden="true" tabindex="-1"></a>svm_sgd <span class="op">=</span> SGDClassifier(</span>
<span id="cb44-1012"><a href="#cb44-1012" aria-hidden="true" tabindex="-1"></a>    loss<span class="op">=</span><span class="st">'hinge'</span>,           <span class="co"># SVM loss</span></span>
<span id="cb44-1013"><a href="#cb44-1013" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.0001</span>,            <span class="co"># Regularization parameter</span></span>
<span id="cb44-1014"><a href="#cb44-1014" aria-hidden="true" tabindex="-1"></a>    max_iter<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb44-1015"><a href="#cb44-1015" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb44-1016"><a href="#cb44-1016" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb44-1017"><a href="#cb44-1017" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-1018"><a href="#cb44-1018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1019"><a href="#cb44-1019" aria-hidden="true" tabindex="-1"></a>svm_sgd.fit(X_train_scaled, y_train_gb)</span>
<span id="cb44-1020"><a href="#cb44-1020" aria-hidden="true" tabindex="-1"></a>y_pred_svm <span class="op">=</span> svm_sgd.predict(X_test_scaled)</span>
<span id="cb44-1021"><a href="#cb44-1021" aria-hidden="true" tabindex="-1"></a>svm_accuracy <span class="op">=</span> accuracy_score(y_test_gb, y_pred_svm)</span>
<span id="cb44-1022"><a href="#cb44-1022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1023"><a href="#cb44-1023" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Linear SVM (SGD) Accuracy: </span><span class="sc">{</span>svm_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb44-1024"><a href="#cb44-1024" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Memory efficient: Suitable for datasets with millions of samples"</span>)</span>
<span id="cb44-1025"><a href="#cb44-1025" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-1026"><a href="#cb44-1026" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1027"><a href="#cb44-1027" aria-hidden="true" tabindex="-1"></a><span class="fu">### Kernel Approximation for Non-Linear SVMs</span></span>
<span id="cb44-1028"><a href="#cb44-1028" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1031"><a href="#cb44-1031" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-1032"><a href="#cb44-1032" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: kernel-approximation</span></span>
<span id="cb44-1033"><a href="#cb44-1033" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-1034"><a href="#cb44-1034" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-1035"><a href="#cb44-1035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1036"><a href="#cb44-1036" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.kernel_approximation <span class="im">import</span> RBFSampler, Nystroem</span>
<span id="cb44-1037"><a href="#cb44-1037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1038"><a href="#cb44-1038" aria-hidden="true" tabindex="-1"></a><span class="co"># RBF Kernel approximation</span></span>
<span id="cb44-1039"><a href="#cb44-1039" aria-hidden="true" tabindex="-1"></a>rbf_sampler <span class="op">=</span> RBFSampler(</span>
<span id="cb44-1040"><a href="#cb44-1040" aria-hidden="true" tabindex="-1"></a>    gamma<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb44-1041"><a href="#cb44-1041" aria-hidden="true" tabindex="-1"></a>    n_components<span class="op">=</span><span class="dv">100</span>,  <span class="co"># Number of random features</span></span>
<span id="cb44-1042"><a href="#cb44-1042" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb44-1043"><a href="#cb44-1043" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-1044"><a href="#cb44-1044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1045"><a href="#cb44-1045" aria-hidden="true" tabindex="-1"></a>X_train_rbf <span class="op">=</span> rbf_sampler.fit_transform(X_train_scaled)</span>
<span id="cb44-1046"><a href="#cb44-1046" aria-hidden="true" tabindex="-1"></a>X_test_rbf <span class="op">=</span> rbf_sampler.transform(X_test_scaled)</span>
<span id="cb44-1047"><a href="#cb44-1047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1048"><a href="#cb44-1048" aria-hidden="true" tabindex="-1"></a>svm_rbf <span class="op">=</span> SGDClassifier(loss<span class="op">=</span><span class="st">'hinge'</span>, alpha<span class="op">=</span><span class="fl">0.0001</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb44-1049"><a href="#cb44-1049" aria-hidden="true" tabindex="-1"></a>svm_rbf.fit(X_train_rbf, y_train_gb)</span>
<span id="cb44-1050"><a href="#cb44-1050" aria-hidden="true" tabindex="-1"></a>y_pred_rbf <span class="op">=</span> svm_rbf.predict(X_test_rbf)</span>
<span id="cb44-1051"><a href="#cb44-1051" aria-hidden="true" tabindex="-1"></a>rbf_accuracy <span class="op">=</span> accuracy_score(y_test_gb, y_pred_rbf)</span>
<span id="cb44-1052"><a href="#cb44-1052" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1053"><a href="#cb44-1053" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"RBF Kernel Approximation Accuracy: </span><span class="sc">{</span>rbf_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb44-1054"><a href="#cb44-1054" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Enables non-linear SVMs on large datasets"</span>)</span>
<span id="cb44-1055"><a href="#cb44-1055" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-1056"><a href="#cb44-1056" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1057"><a href="#cb44-1057" aria-hidden="true" tabindex="-1"></a><span class="fu">## Neural Networks for Large-Scale Learning</span></span>
<span id="cb44-1058"><a href="#cb44-1058" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1059"><a href="#cb44-1059" aria-hidden="true" tabindex="-1"></a>Deep learning approaches, particularly feedforward neural networks, can effectively handle large datasets when properly configured with regularization and efficient optimization.</span>
<span id="cb44-1060"><a href="#cb44-1060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1061"><a href="#cb44-1061" aria-hidden="true" tabindex="-1"></a><span class="fu">### Multi-Layer Perceptron with scikit-learn</span></span>
<span id="cb44-1062"><a href="#cb44-1062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1065"><a href="#cb44-1065" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-1066"><a href="#cb44-1066" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: mlp-classifier</span></span>
<span id="cb44-1067"><a href="#cb44-1067" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-1068"><a href="#cb44-1068" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-1069"><a href="#cb44-1069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1070"><a href="#cb44-1070" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb44-1071"><a href="#cb44-1071" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1072"><a href="#cb44-1072" aria-hidden="true" tabindex="-1"></a><span class="co"># Multi-layer Perceptron</span></span>
<span id="cb44-1073"><a href="#cb44-1073" aria-hidden="true" tabindex="-1"></a>mlp <span class="op">=</span> MLPClassifier(</span>
<span id="cb44-1074"><a href="#cb44-1074" aria-hidden="true" tabindex="-1"></a>    hidden_layer_sizes<span class="op">=</span>(<span class="dv">100</span>, <span class="dv">50</span>),  <span class="co"># Two hidden layers</span></span>
<span id="cb44-1075"><a href="#cb44-1075" aria-hidden="true" tabindex="-1"></a>    activation<span class="op">=</span><span class="st">'relu'</span>,</span>
<span id="cb44-1076"><a href="#cb44-1076" aria-hidden="true" tabindex="-1"></a>    solver<span class="op">=</span><span class="st">'adam'</span>,                <span class="co"># Efficient for large datasets</span></span>
<span id="cb44-1077"><a href="#cb44-1077" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.0001</span>,                 <span class="co"># L2 regularization</span></span>
<span id="cb44-1078"><a href="#cb44-1078" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">200</span>,               <span class="co"># Mini-batch size</span></span>
<span id="cb44-1079"><a href="#cb44-1079" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="st">'adaptive'</span>,</span>
<span id="cb44-1080"><a href="#cb44-1080" aria-hidden="true" tabindex="-1"></a>    max_iter<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb44-1081"><a href="#cb44-1081" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb44-1082"><a href="#cb44-1082" aria-hidden="true" tabindex="-1"></a>    early_stopping<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb44-1083"><a href="#cb44-1083" aria-hidden="true" tabindex="-1"></a>    validation_fraction<span class="op">=</span><span class="fl">0.1</span></span>
<span id="cb44-1084"><a href="#cb44-1084" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-1085"><a href="#cb44-1085" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1086"><a href="#cb44-1086" aria-hidden="true" tabindex="-1"></a>mlp.fit(X_train_scaled, y_train_gb)</span>
<span id="cb44-1087"><a href="#cb44-1087" aria-hidden="true" tabindex="-1"></a>y_pred_mlp <span class="op">=</span> mlp.predict(X_test_scaled)</span>
<span id="cb44-1088"><a href="#cb44-1088" aria-hidden="true" tabindex="-1"></a>mlp_accuracy <span class="op">=</span> accuracy_score(y_test_gb, y_pred_mlp)</span>
<span id="cb44-1089"><a href="#cb44-1089" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1090"><a href="#cb44-1090" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MLP Accuracy: </span><span class="sc">{</span>mlp_accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb44-1091"><a href="#cb44-1091" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Architecture: </span><span class="sc">{</span>mlp<span class="sc">.</span>hidden_layer_sizes<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-1092"><a href="#cb44-1092" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of iterations: </span><span class="sc">{</span>mlp<span class="sc">.</span>n_iter_<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb44-1093"><a href="#cb44-1093" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-1094"><a href="#cb44-1094" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1095"><a href="#cb44-1095" aria-hidden="true" tabindex="-1"></a><span class="fu">### Deep Learning with TensorFlow/Keras (Optional)</span></span>
<span id="cb44-1096"><a href="#cb44-1096" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1099"><a href="#cb44-1099" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-1100"><a href="#cb44-1100" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: deep-learning</span></span>
<span id="cb44-1101"><a href="#cb44-1101" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-1102"><a href="#cb44-1102" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb44-1103"><a href="#cb44-1103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1104"><a href="#cb44-1104" aria-hidden="true" tabindex="-1"></a><span class="co"># Uncomment to use TensorFlow/Keras</span></span>
<span id="cb44-1105"><a href="#cb44-1105" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb44-1106"><a href="#cb44-1106" aria-hidden="true" tabindex="-1"></a><span class="co">try:</span></span>
<span id="cb44-1107"><a href="#cb44-1107" aria-hidden="true" tabindex="-1"></a><span class="co">    import tensorflow as tf</span></span>
<span id="cb44-1108"><a href="#cb44-1108" aria-hidden="true" tabindex="-1"></a><span class="co">    from tensorflow import keras</span></span>
<span id="cb44-1109"><a href="#cb44-1109" aria-hidden="true" tabindex="-1"></a><span class="co">    from tensorflow.keras import layers</span></span>
<span id="cb44-1110"><a href="#cb44-1110" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb44-1111"><a href="#cb44-1111" aria-hidden="true" tabindex="-1"></a><span class="co">    # Build neural network</span></span>
<span id="cb44-1112"><a href="#cb44-1112" aria-hidden="true" tabindex="-1"></a><span class="co">    model = keras.Sequential([</span></span>
<span id="cb44-1113"><a href="#cb44-1113" aria-hidden="true" tabindex="-1"></a><span class="co">        layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),</span></span>
<span id="cb44-1114"><a href="#cb44-1114" aria-hidden="true" tabindex="-1"></a><span class="co">        layers.Dropout(0.3),</span></span>
<span id="cb44-1115"><a href="#cb44-1115" aria-hidden="true" tabindex="-1"></a><span class="co">        layers.Dense(64, activation='relu'),</span></span>
<span id="cb44-1116"><a href="#cb44-1116" aria-hidden="true" tabindex="-1"></a><span class="co">        layers.Dropout(0.3),</span></span>
<span id="cb44-1117"><a href="#cb44-1117" aria-hidden="true" tabindex="-1"></a><span class="co">        layers.Dense(1, activation='sigmoid')</span></span>
<span id="cb44-1118"><a href="#cb44-1118" aria-hidden="true" tabindex="-1"></a><span class="co">    ])</span></span>
<span id="cb44-1119"><a href="#cb44-1119" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb44-1120"><a href="#cb44-1120" aria-hidden="true" tabindex="-1"></a><span class="co">    model.compile(</span></span>
<span id="cb44-1121"><a href="#cb44-1121" aria-hidden="true" tabindex="-1"></a><span class="co">        optimizer='adam',</span></span>
<span id="cb44-1122"><a href="#cb44-1122" aria-hidden="true" tabindex="-1"></a><span class="co">        loss='binary_crossentropy',</span></span>
<span id="cb44-1123"><a href="#cb44-1123" aria-hidden="true" tabindex="-1"></a><span class="co">        metrics=['accuracy']</span></span>
<span id="cb44-1124"><a href="#cb44-1124" aria-hidden="true" tabindex="-1"></a><span class="co">    )</span></span>
<span id="cb44-1125"><a href="#cb44-1125" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb44-1126"><a href="#cb44-1126" aria-hidden="true" tabindex="-1"></a><span class="co">    # Train model</span></span>
<span id="cb44-1127"><a href="#cb44-1127" aria-hidden="true" tabindex="-1"></a><span class="co">    history = model.fit(</span></span>
<span id="cb44-1128"><a href="#cb44-1128" aria-hidden="true" tabindex="-1"></a><span class="co">        X_train_scaled, y_train_gb,</span></span>
<span id="cb44-1129"><a href="#cb44-1129" aria-hidden="true" tabindex="-1"></a><span class="co">        epochs=50,</span></span>
<span id="cb44-1130"><a href="#cb44-1130" aria-hidden="true" tabindex="-1"></a><span class="co">        batch_size=256,</span></span>
<span id="cb44-1131"><a href="#cb44-1131" aria-hidden="true" tabindex="-1"></a><span class="co">        validation_split=0.2,</span></span>
<span id="cb44-1132"><a href="#cb44-1132" aria-hidden="true" tabindex="-1"></a><span class="co">        verbose=0</span></span>
<span id="cb44-1133"><a href="#cb44-1133" aria-hidden="true" tabindex="-1"></a><span class="co">    )</span></span>
<span id="cb44-1134"><a href="#cb44-1134" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb44-1135"><a href="#cb44-1135" aria-hidden="true" tabindex="-1"></a><span class="co">    # Evaluate</span></span>
<span id="cb44-1136"><a href="#cb44-1136" aria-hidden="true" tabindex="-1"></a><span class="co">    test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test_gb, verbose=0)</span></span>
<span id="cb44-1137"><a href="#cb44-1137" aria-hidden="true" tabindex="-1"></a><span class="co">    print(f"Deep Neural Network Accuracy: {test_accuracy:.4f}")</span></span>
<span id="cb44-1138"><a href="#cb44-1138" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb44-1139"><a href="#cb44-1139" aria-hidden="true" tabindex="-1"></a><span class="co">except ImportError:</span></span>
<span id="cb44-1140"><a href="#cb44-1140" aria-hidden="true" tabindex="-1"></a><span class="co">    print("TensorFlow not installed. Install with: pip install tensorflow")</span></span>
<span id="cb44-1141"><a href="#cb44-1141" aria-hidden="true" tabindex="-1"></a><span class="co">"""</span></span>
<span id="cb44-1142"><a href="#cb44-1142" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-1143"><a href="#cb44-1143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1144"><a href="#cb44-1144" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regularized Linear Models</span></span>
<span id="cb44-1145"><a href="#cb44-1145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1146"><a href="#cb44-1146" aria-hidden="true" tabindex="-1"></a>Linear models with regularization (Ridge, Lasso, Elastic Net) are highly scalable and provide interpretable results, making them excellent baselines for large-scale problems.</span>
<span id="cb44-1147"><a href="#cb44-1147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1148"><a href="#cb44-1148" aria-hidden="true" tabindex="-1"></a><span class="fu">### Ridge Regression</span></span>
<span id="cb44-1149"><a href="#cb44-1149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1152"><a href="#cb44-1152" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-1153"><a href="#cb44-1153" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: ridge-regression</span></span>
<span id="cb44-1154"><a href="#cb44-1154" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-1155"><a href="#cb44-1155" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-1156"><a href="#cb44-1156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1157"><a href="#cb44-1157" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Ridge, RidgeClassifier</span>
<span id="cb44-1158"><a href="#cb44-1158" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span>
<span id="cb44-1159"><a href="#cb44-1159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1160"><a href="#cb44-1160" aria-hidden="true" tabindex="-1"></a><span class="co"># Ridge Regression for continuous targets</span></span>
<span id="cb44-1161"><a href="#cb44-1161" aria-hidden="true" tabindex="-1"></a>X_reg_train, X_reg_test, y_reg_train, y_reg_test <span class="op">=</span> train_test_split(</span>
<span id="cb44-1162"><a href="#cb44-1162" aria-hidden="true" tabindex="-1"></a>    X_reg, y_reg, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb44-1163"><a href="#cb44-1163" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-1164"><a href="#cb44-1164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1165"><a href="#cb44-1165" aria-hidden="true" tabindex="-1"></a>ridge_reg <span class="op">=</span> Ridge(alpha<span class="op">=</span><span class="fl">1.0</span>, solver<span class="op">=</span><span class="st">'sag'</span>, random_state<span class="op">=</span><span class="dv">42</span>)  <span class="co"># SAG for large datasets</span></span>
<span id="cb44-1166"><a href="#cb44-1166" aria-hidden="true" tabindex="-1"></a>ridge_reg.fit(X_reg_train, y_reg_train)</span>
<span id="cb44-1167"><a href="#cb44-1167" aria-hidden="true" tabindex="-1"></a>y_pred_ridge <span class="op">=</span> ridge_reg.predict(X_reg_test)</span>
<span id="cb44-1168"><a href="#cb44-1168" aria-hidden="true" tabindex="-1"></a>ridge_r2 <span class="op">=</span> r2_score(y_reg_test, y_pred_ridge)</span>
<span id="cb44-1169"><a href="#cb44-1169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1170"><a href="#cb44-1170" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Ridge Regression R²: </span><span class="sc">{</span>ridge_r2<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb44-1171"><a href="#cb44-1171" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Highly scalable to millions of samples"</span>)</span>
<span id="cb44-1172"><a href="#cb44-1172" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-1173"><a href="#cb44-1173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1174"><a href="#cb44-1174" aria-hidden="true" tabindex="-1"></a><span class="fu">### Elastic Net: Combining L1 and L2 Regularization</span></span>
<span id="cb44-1175"><a href="#cb44-1175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1178"><a href="#cb44-1178" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-1179"><a href="#cb44-1179" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: elastic-net</span></span>
<span id="cb44-1180"><a href="#cb44-1180" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-1181"><a href="#cb44-1181" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-1182"><a href="#cb44-1182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1183"><a href="#cb44-1183" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> ElasticNet, ElasticNetCV</span>
<span id="cb44-1184"><a href="#cb44-1184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1185"><a href="#cb44-1185" aria-hidden="true" tabindex="-1"></a><span class="co"># Elastic Net with cross-validation for hyperparameter tuning</span></span>
<span id="cb44-1186"><a href="#cb44-1186" aria-hidden="true" tabindex="-1"></a>elastic_net <span class="op">=</span> ElasticNetCV(</span>
<span id="cb44-1187"><a href="#cb44-1187" aria-hidden="true" tabindex="-1"></a>    l1_ratio<span class="op">=</span>[<span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>, <span class="fl">0.9</span>, <span class="fl">0.95</span>, <span class="fl">0.99</span>, <span class="fl">1.0</span>],</span>
<span id="cb44-1188"><a href="#cb44-1188" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb44-1189"><a href="#cb44-1189" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb44-1190"><a href="#cb44-1190" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb44-1191"><a href="#cb44-1191" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-1192"><a href="#cb44-1192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1193"><a href="#cb44-1193" aria-hidden="true" tabindex="-1"></a>elastic_net.fit(X_reg_train, y_reg_train)</span>
<span id="cb44-1194"><a href="#cb44-1194" aria-hidden="true" tabindex="-1"></a>y_pred_en <span class="op">=</span> elastic_net.predict(X_reg_test)</span>
<span id="cb44-1195"><a href="#cb44-1195" aria-hidden="true" tabindex="-1"></a>en_r2 <span class="op">=</span> r2_score(y_reg_test, y_pred_en)</span>
<span id="cb44-1196"><a href="#cb44-1196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1197"><a href="#cb44-1197" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Elastic Net R²: </span><span class="sc">{</span>en_r2<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb44-1198"><a href="#cb44-1198" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimal L1 ratio: </span><span class="sc">{</span>elastic_net<span class="sc">.</span>l1_ratio_<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb44-1199"><a href="#cb44-1199" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Combines benefits of Ridge and Lasso regularization"</span>)</span>
<span id="cb44-1200"><a href="#cb44-1200" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-1201"><a href="#cb44-1201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1202"><a href="#cb44-1202" aria-hidden="true" tabindex="-1"></a><span class="fu">### Lasso for Feature Selection</span></span>
<span id="cb44-1203"><a href="#cb44-1203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1206"><a href="#cb44-1206" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-1207"><a href="#cb44-1207" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: lasso-feature-selection</span></span>
<span id="cb44-1208"><a href="#cb44-1208" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-1209"><a href="#cb44-1209" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-1210"><a href="#cb44-1210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1211"><a href="#cb44-1211" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Lasso, LassoCV</span>
<span id="cb44-1212"><a href="#cb44-1212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1213"><a href="#cb44-1213" aria-hidden="true" tabindex="-1"></a><span class="co"># Lasso with cross-validation</span></span>
<span id="cb44-1214"><a href="#cb44-1214" aria-hidden="true" tabindex="-1"></a>lasso <span class="op">=</span> LassoCV(cv<span class="op">=</span><span class="dv">5</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>, max_iter<span class="op">=</span><span class="dv">2000</span>)</span>
<span id="cb44-1215"><a href="#cb44-1215" aria-hidden="true" tabindex="-1"></a>lasso.fit(X_reg_train, y_reg_train)</span>
<span id="cb44-1216"><a href="#cb44-1216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1217"><a href="#cb44-1217" aria-hidden="true" tabindex="-1"></a><span class="co"># Count non-zero coefficients (selected features)</span></span>
<span id="cb44-1218"><a href="#cb44-1218" aria-hidden="true" tabindex="-1"></a>n_selected <span class="op">=</span> np.<span class="bu">sum</span>(lasso.coef_ <span class="op">!=</span> <span class="dv">0</span>)</span>
<span id="cb44-1219"><a href="#cb44-1219" aria-hidden="true" tabindex="-1"></a>total_features <span class="op">=</span> <span class="bu">len</span>(lasso.coef_)</span>
<span id="cb44-1220"><a href="#cb44-1220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1221"><a href="#cb44-1221" aria-hidden="true" tabindex="-1"></a>y_pred_lasso <span class="op">=</span> lasso.predict(X_reg_test)</span>
<span id="cb44-1222"><a href="#cb44-1222" aria-hidden="true" tabindex="-1"></a>lasso_r2 <span class="op">=</span> r2_score(y_reg_test, y_pred_lasso)</span>
<span id="cb44-1223"><a href="#cb44-1223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1224"><a href="#cb44-1224" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Lasso R²: </span><span class="sc">{</span>lasso_r2<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb44-1225"><a href="#cb44-1225" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Selected features: </span><span class="sc">{</span>n_selected<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>total_features<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span>n_selected<span class="op">/</span>total_features<span class="sc">:.1f}</span><span class="ss">%)"</span>)</span>
<span id="cb44-1226"><a href="#cb44-1226" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Automatic feature selection through L1 regularization"</span>)</span>
<span id="cb44-1227"><a href="#cb44-1227" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-1228"><a href="#cb44-1228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1229"><a href="#cb44-1229" aria-hidden="true" tabindex="-1"></a><span class="fu">## Comparative Analysis of ML Techniques</span></span>
<span id="cb44-1230"><a href="#cb44-1230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1231"><a href="#cb44-1231" aria-hidden="true" tabindex="-1"></a><span class="fu">### Performance Comparison on Large Datasets</span></span>
<span id="cb44-1232"><a href="#cb44-1232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1235"><a href="#cb44-1235" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-1236"><a href="#cb44-1236" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: ml-comparison</span></span>
<span id="cb44-1237"><a href="#cb44-1237" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-1238"><a href="#cb44-1238" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Comparison of ML Techniques on Large-Scale Dataset"</span></span>
<span id="cb44-1239"><a href="#cb44-1239" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 6</span></span>
<span id="cb44-1240"><a href="#cb44-1240" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 10</span></span>
<span id="cb44-1241"><a href="#cb44-1241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1242"><a href="#cb44-1242" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare multiple algorithms</span></span>
<span id="cb44-1243"><a href="#cb44-1243" aria-hidden="true" tabindex="-1"></a>algorithms <span class="op">=</span> {}</span>
<span id="cb44-1244"><a href="#cb44-1244" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> {}</span>
<span id="cb44-1245"><a href="#cb44-1245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1246"><a href="#cb44-1246" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest</span></span>
<span id="cb44-1247"><a href="#cb44-1247" aria-hidden="true" tabindex="-1"></a>rf_comp <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb44-1248"><a href="#cb44-1248" aria-hidden="true" tabindex="-1"></a>rf_comp.fit(X_train_gb[:<span class="dv">20000</span>], y_train_gb[:<span class="dv">20000</span>])</span>
<span id="cb44-1249"><a href="#cb44-1249" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'Random Forest'</span>] <span class="op">=</span> accuracy_score(y_test_gb, rf_comp.predict(X_test_gb))</span>
<span id="cb44-1250"><a href="#cb44-1250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1251"><a href="#cb44-1251" aria-hidden="true" tabindex="-1"></a><span class="co"># XGBoost</span></span>
<span id="cb44-1252"><a href="#cb44-1252" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb44-1253"><a href="#cb44-1253" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb44-1254"><a href="#cb44-1254" aria-hidden="true" tabindex="-1"></a>    xgb_comp <span class="op">=</span> xgb.XGBClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, random_state<span class="op">=</span><span class="dv">42</span>, tree_method<span class="op">=</span><span class="st">'hist'</span>)</span>
<span id="cb44-1255"><a href="#cb44-1255" aria-hidden="true" tabindex="-1"></a>    xgb_comp.fit(X_train_gb[:<span class="dv">20000</span>], y_train_gb[:<span class="dv">20000</span>])</span>
<span id="cb44-1256"><a href="#cb44-1256" aria-hidden="true" tabindex="-1"></a>    results[<span class="st">'XGBoost'</span>] <span class="op">=</span> accuracy_score(y_test_gb, xgb_comp.predict(X_test_gb))</span>
<span id="cb44-1257"><a href="#cb44-1257" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ImportError</span>:</span>
<span id="cb44-1258"><a href="#cb44-1258" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb44-1259"><a href="#cb44-1259" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb44-1260"><a href="#cb44-1260" aria-hidden="true" tabindex="-1"></a>    <span class="cf">pass</span></span>
<span id="cb44-1261"><a href="#cb44-1261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1262"><a href="#cb44-1262" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear SVM</span></span>
<span id="cb44-1263"><a href="#cb44-1263" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'Linear SVM'</span>] <span class="op">=</span> svm_accuracy</span>
<span id="cb44-1264"><a href="#cb44-1264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1265"><a href="#cb44-1265" aria-hidden="true" tabindex="-1"></a><span class="co"># MLP</span></span>
<span id="cb44-1266"><a href="#cb44-1266" aria-hidden="true" tabindex="-1"></a>results[<span class="st">'MLP'</span>] <span class="op">=</span> mlp_accuracy</span>
<span id="cb44-1267"><a href="#cb44-1267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1268"><a href="#cb44-1268" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize comparison</span></span>
<span id="cb44-1269"><a href="#cb44-1269" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> results:</span>
<span id="cb44-1270"><a href="#cb44-1270" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb44-1271"><a href="#cb44-1271" aria-hidden="true" tabindex="-1"></a>    algorithms <span class="op">=</span> <span class="bu">list</span>(results.keys())</span>
<span id="cb44-1272"><a href="#cb44-1272" aria-hidden="true" tabindex="-1"></a>    accuracies <span class="op">=</span> <span class="bu">list</span>(results.values())</span>
<span id="cb44-1273"><a href="#cb44-1273" aria-hidden="true" tabindex="-1"></a>    colors <span class="op">=</span> [<span class="st">'#667eea'</span>, <span class="st">'#764ba2'</span>, <span class="st">'#f093fb'</span>, <span class="st">'#4facfe'</span>, <span class="st">'#00f2fe'</span>]</span>
<span id="cb44-1274"><a href="#cb44-1274" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-1275"><a href="#cb44-1275" aria-hidden="true" tabindex="-1"></a>    bars <span class="op">=</span> plt.bar(algorithms, accuracies, color<span class="op">=</span>colors[:<span class="bu">len</span>(algorithms)])</span>
<span id="cb44-1276"><a href="#cb44-1276" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb44-1277"><a href="#cb44-1277" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Machine Learning Algorithm Comparison'</span>)</span>
<span id="cb44-1278"><a href="#cb44-1278" aria-hidden="true" tabindex="-1"></a>    plt.ylim([<span class="bu">min</span>(accuracies) <span class="op">-</span> <span class="fl">0.05</span>, <span class="bu">max</span>(accuracies) <span class="op">+</span> <span class="fl">0.05</span>])</span>
<span id="cb44-1279"><a href="#cb44-1279" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-1280"><a href="#cb44-1280" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add value labels on bars</span></span>
<span id="cb44-1281"><a href="#cb44-1281" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> bar, acc <span class="kw">in</span> <span class="bu">zip</span>(bars, accuracies):</span>
<span id="cb44-1282"><a href="#cb44-1282" aria-hidden="true" tabindex="-1"></a>        plt.text(bar.get_x() <span class="op">+</span> bar.get_width()<span class="op">/</span><span class="dv">2</span>, bar.get_height() <span class="op">+</span> <span class="fl">0.01</span>,</span>
<span id="cb44-1283"><a href="#cb44-1283" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f'</span><span class="sc">{</span>acc<span class="sc">:.3f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>)</span>
<span id="cb44-1284"><a href="#cb44-1284" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb44-1285"><a href="#cb44-1285" aria-hidden="true" tabindex="-1"></a>    plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb44-1286"><a href="#cb44-1286" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb44-1287"><a href="#cb44-1287" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb44-1288"><a href="#cb44-1288" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-1289"><a href="#cb44-1289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1290"><a href="#cb44-1290" aria-hidden="true" tabindex="-1"></a><span class="fu">## When to Use Each Technique</span></span>
<span id="cb44-1291"><a href="#cb44-1291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1292"><a href="#cb44-1292" aria-hidden="true" tabindex="-1"></a><span class="fu">### Decision Guide</span></span>
<span id="cb44-1293"><a href="#cb44-1293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1294"><a href="#cb44-1294" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Technique <span class="pp">|</span> Best For <span class="pp">|</span> Strengths <span class="pp">|</span> Limitations <span class="pp">|</span></span>
<span id="cb44-1295"><a href="#cb44-1295" aria-hidden="true" tabindex="-1"></a><span class="pp">|-----------|----------|-----------|-------------|</span></span>
<span id="cb44-1296"><a href="#cb44-1296" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Random Forest** <span class="pp">|</span> Baseline, feature importance, interpretability <span class="pp">|</span> Robust, parallelizable, handles mixed data types <span class="pp">|</span> Memory intensive, slower than gradient boosting <span class="pp">|</span></span>
<span id="cb44-1297"><a href="#cb44-1297" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **XGBoost/LightGBM** <span class="pp">|</span> High accuracy, competitions, structured data <span class="pp">|</span> State-of-the-art performance, efficient <span class="pp">|</span> More hyperparameters, less interpretable <span class="pp">|</span></span>
<span id="cb44-1298"><a href="#cb44-1298" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Linear SVM** <span class="pp">|</span> Text classification, high-dimensional sparse data <span class="pp">|</span> Memory efficient, fast training <span class="pp">|</span> Limited to linear or approximated kernels <span class="pp">|</span></span>
<span id="cb44-1299"><a href="#cb44-1299" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Neural Networks** <span class="pp">|</span> Complex patterns, unstructured data <span class="pp">|</span> Flexible, can learn non-linear relationships <span class="pp">|</span> Requires more data, longer training time <span class="pp">|</span></span>
<span id="cb44-1300"><a href="#cb44-1300" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Regularized Linear Models** <span class="pp">|</span> Baseline, interpretability, feature selection <span class="pp">|</span> Fast, interpretable, scalable <span class="pp">|</span> Limited to linear relationships <span class="pp">|</span></span>
<span id="cb44-1301"><a href="#cb44-1301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1302"><a href="#cb44-1302" aria-hidden="true" tabindex="-1"></a><span class="fu">### Scalability Considerations</span></span>
<span id="cb44-1303"><a href="#cb44-1303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1306"><a href="#cb44-1306" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb44-1307"><a href="#cb44-1307" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: scalability-analysis</span></span>
<span id="cb44-1308"><a href="#cb44-1308" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb44-1309"><a href="#cb44-1309" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: true</span></span>
<span id="cb44-1310"><a href="#cb44-1310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1311"><a href="#cb44-1311" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Scalability Analysis for Large Datasets:"</span>)</span>
<span id="cb44-1312"><a href="#cb44-1312" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">1. Random Forest:"</span>)</span>
<span id="cb44-1313"><a href="#cb44-1313" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Memory: O(n × m × trees)"</span>)</span>
<span id="cb44-1314"><a href="#cb44-1314" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Training: O(n × m × log(m) × trees)"</span>)</span>
<span id="cb44-1315"><a href="#cb44-1315" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Parallelizable: Yes"</span>)</span>
<span id="cb44-1316"><a href="#cb44-1316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1317"><a href="#cb44-1317" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">2. Gradient Boosting (XGBoost/LightGBM):"</span>)</span>
<span id="cb44-1318"><a href="#cb44-1318" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Memory: O(n × m)"</span>)</span>
<span id="cb44-1319"><a href="#cb44-1319" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Training: O(n × m × log(m) × iterations)"</span>)</span>
<span id="cb44-1320"><a href="#cb44-1320" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Parallelizable: Yes (tree-level)"</span>)</span>
<span id="cb44-1321"><a href="#cb44-1321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1322"><a href="#cb44-1322" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">3. Linear SVM (SGD):"</span>)</span>
<span id="cb44-1323"><a href="#cb44-1323" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Memory: O(m)"</span>)</span>
<span id="cb44-1324"><a href="#cb44-1324" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Training: O(n × m × iterations)"</span>)</span>
<span id="cb44-1325"><a href="#cb44-1325" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Parallelizable: Yes (sample-level)"</span>)</span>
<span id="cb44-1326"><a href="#cb44-1326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1327"><a href="#cb44-1327" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">4. Neural Networks:"</span>)</span>
<span id="cb44-1328"><a href="#cb44-1328" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Memory: O(parameters)"</span>)</span>
<span id="cb44-1329"><a href="#cb44-1329" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Training: O(n × parameters × epochs)"</span>)</span>
<span id="cb44-1330"><a href="#cb44-1330" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Parallelizable: Yes (GPU acceleration)"</span>)</span>
<span id="cb44-1331"><a href="#cb44-1331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1332"><a href="#cb44-1332" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">5. Regularized Linear Models:"</span>)</span>
<span id="cb44-1333"><a href="#cb44-1333" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Memory: O(m)"</span>)</span>
<span id="cb44-1334"><a href="#cb44-1334" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Training: O(n × m × iterations)"</span>)</span>
<span id="cb44-1335"><a href="#cb44-1335" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Parallelizable: Yes"</span>)</span>
<span id="cb44-1336"><a href="#cb44-1336" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb44-1337"><a href="#cb44-1337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1338"><a href="#cb44-1338" aria-hidden="true" tabindex="-1"></a><span class="fu">## Conclusion</span></span>
<span id="cb44-1339"><a href="#cb44-1339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1340"><a href="#cb44-1340" aria-hidden="true" tabindex="-1"></a>Random Forest algorithms represent a powerful and versatile tool in the machine learning practitioner's toolkit. Through bootstrap aggregation and random feature selection, these ensemble methods achieve robust performance across diverse application domains while maintaining computational efficiency and interpretability through feature importance measures.</span>
<span id="cb44-1341"><a href="#cb44-1341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1342"><a href="#cb44-1342" aria-hidden="true" tabindex="-1"></a>The demonstrated implementations illustrate key aspects of Random Forest methodology, including hyperparameter optimization, handling of large-scale datasets, and performance evaluation. As machine learning continues to evolve, Random Forests remain a reliable baseline method, particularly valuable for their ability to handle high-dimensional data, provide feature importance insights, and deliver strong predictive performance with minimal preprocessing requirements.</span>
<span id="cb44-1343"><a href="#cb44-1343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1344"><a href="#cb44-1344" aria-hidden="true" tabindex="-1"></a><span class="fu">### Key Takeaways</span></span>
<span id="cb44-1345"><a href="#cb44-1345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1346"><a href="#cb44-1346" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Random Forests excel at handling large, high-dimensional datasets</span>
<span id="cb44-1347"><a href="#cb44-1347" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Feature importance measures provide valuable interpretability</span>
<span id="cb44-1348"><a href="#cb44-1348" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Proper hyperparameter tuning significantly impacts performance</span>
<span id="cb44-1349"><a href="#cb44-1349" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Parallel processing enables efficient training on large datasets</span>
<span id="cb44-1350"><a href="#cb44-1350" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The method serves as an excellent baseline for comparison with more complex models</span>
<span id="cb44-1351"><a href="#cb44-1351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1352"><a href="#cb44-1352" aria-hidden="true" tabindex="-1"></a><span class="fu">## References</span></span>
<span id="cb44-1353"><a href="#cb44-1353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1354"><a href="#cb44-1354" aria-hidden="true" tabindex="-1"></a>All cited literature is listed in the Literature Review section above. For comprehensive bibliographic information, readers are encouraged to consult the original publications through their respective digital object identifiers (DOIs) or publication URLs.</span>
<span id="cb44-1355"><a href="#cb44-1355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1356"><a href="#cb44-1356" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb44-1357"><a href="#cb44-1357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-1358"><a href="#cb44-1358" aria-hidden="true" tabindex="-1"></a>*This document was generated using Quarto. For reproducible research, all code chunks can be executed to regenerate the analyses and visualizations presented herein.*</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>